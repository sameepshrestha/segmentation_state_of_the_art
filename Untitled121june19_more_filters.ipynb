{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled121june19-more-filters.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sameepshrestha/segmentation_state_of_the_art/blob/main/Untitled121june19_more_filters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kTMpcSd1YrH"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPSbYPZyCIvP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4da340f-d02c-488b-e954-9ecb12d8b648"
      },
      "source": [
        "# model.summary()\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXMEt7jkCaVW"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "import numpy as np \n",
        "import cv2 as cv \n",
        "from PIL import Image, ImageDraw\n",
        "import json \n",
        "import os \n",
        "import glob \n",
        "import re \n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf \n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Reshape, Concatenate,MaxPooling2D, AveragePooling2D,Input, BatchNormalization, Activation, UpSampling2D, Concatenate, LeakyReLU,Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D,multiply\n",
        "from tensorflow.keras.optimizers import Adam \n",
        "#using tensorflow backend 16 so keras backend still 32bytes so no keras to be used\n",
        "# from keras.layers.merge import concatenate,Concatenate\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gc\n",
        "import psutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_maY0bRpS38"
      },
      "source": [
        "import math\n",
        "import sys, time\n",
        "\n",
        "# Interpolation kernel\n",
        "def u(s,a):\n",
        "    if (abs(s) >=0) & (abs(s) <=1):\n",
        "        return (a+2)*(abs(s)**3)-(a+3)*(abs(s)**2)+1\n",
        "    elif (abs(s) > 1) & (abs(s) <= 2):\n",
        "        return a*(abs(s)**3)-(5*a)*(abs(s)**2)+(8*a)*abs(s)-4*a\n",
        "    return 0\n",
        "\n",
        "#Paddnig\n",
        "def padding(img,H,W,C):\n",
        "    zimg = np.zeros((H+4,W+4,C))\n",
        "    zimg[2:H+2,2:W+2,:C] = img\n",
        "    zimg[2:H+2,0:2,:C]=img[:,0:1,:C]\n",
        "    zimg[H+2:H+4,2:W+2,:]=img[H-1:H,:,:]\n",
        "    zimg[2:H+2,W+2:W+4,:]=img[:,W-1:W,:]\n",
        "    zimg[0:2,2:W+2,:C]=img[0:1,:,:C]\n",
        "    zimg[0:2,0:2,:C]=img[0,0,:C]\n",
        "    zimg[H+2:H+4,0:2,:C]=img[H-1,0,:C]\n",
        "    zimg[H+2:H+4,W+2:W+4,:C]=img[H-1,W-1,:C]\n",
        "    zimg[0:2,W+2:W+4,:C]=img[0,W-1,:C]\n",
        "    return zimg\n",
        "\n",
        "# https://github.com/rootpine\n",
        "# Bicubic operation\n",
        "def UPsampling_cubic(img, ratio, a):\n",
        "    #Get image size\n",
        "    H,W,C = img.shape\n",
        "\n",
        "    img = padding(img,H,W,C)\n",
        "    #Create new image\n",
        "    dH = math.floor(H*ratio)\n",
        "    dW = math.floor(W*ratio)\n",
        "    dst = np.zeros((dH, dW, 3))\n",
        "\n",
        "    h = 1/ratio\n",
        "\n",
        "    print('Start bicubic interpolation')\n",
        "    print('It will take a little while...')\n",
        "    inc = 0\n",
        "    for c in range(C):\n",
        "        for j in range(dH):\n",
        "            for i in range(dW):\n",
        "                x, y = i * h + 2 , j * h + 2\n",
        "\n",
        "                x1 = 1 + x - math.floor(x)\n",
        "                x2 = x - math.floor(x)\n",
        "                x3 = math.floor(x) + 1 - x\n",
        "                x4 = math.floor(x) + 2 - x\n",
        "\n",
        "                y1 = 1 + y - math.floor(y)\n",
        "                y2 = y - math.floor(y)\n",
        "                y3 = math.floor(y) + 1 - y\n",
        "                y4 = math.floor(y) + 2 - y\n",
        "\n",
        "                mat_l = np.matrix([[u(x1,a),u(x2,a),u(x3,a),u(x4,a)]])\n",
        "                mat_m = np.matrix([[img[int(y-y1),int(x-x1),c],img[int(y-y2),int(x-x1),c],img[int(y+y3),int(x-x1),c],img[int(y+y4),int(x-x1),c]],\n",
        "                                   [img[int(y-y1),int(x-x2),c],img[int(y-y2),int(x-x2),c],img[int(y+y3),int(x-x2),c],img[int(y+y4),int(x-x2),c]],\n",
        "                                   [img[int(y-y1),int(x+x3),c],img[int(y-y2),int(x+x3),c],img[int(y+y3),int(x+x3),c],img[int(y+y4),int(x+x3),c]],\n",
        "                                   [img[int(y-y1),int(x+x4),c],img[int(y-y2),int(x+x4),c],img[int(y+y3),int(x+x4),c],img[int(y+y4),int(x+x4),c]]])\n",
        "                mat_r = np.matrix([[u(y1,a)],[u(y2,a)],[u(y3,a)],[u(y4,a)]])\n",
        "                dst[j, i, c] = np.dot(np.dot(mat_l, mat_m),mat_r)\n",
        "    return dst\n",
        "\n",
        "# Read image\n",
        "img = cv.imread('butterfly.png')\n",
        "\n",
        "# Scale factor\n",
        "ratio = 2\n",
        "# Coefficient\n",
        "a = -1/2\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jYMHKtEL-oK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e473f7f0-1cea-494c-efa8-d18f77361783"
      },
      "source": [
        "tf.keras.mixed_precision.experimental.set_policy('mixed_float16')\n",
        "# # tf.compat.v1.disable_eager_execution()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
            "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Jl9K0TuK0kZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbd00144-7e11-4ee1-e5c7-a4edf59793fa"
      },
      "source": [
        "category = \"\"\"wall, floor, cabinet, bed, chair, sofa, table, door, window, bookshelf, picture, counter, blinds, desk, shelves, curtain, dresser\n",
        ", pillow, mirror, floor mat, clothes, ceiling, books, fridge, tv, paper, towel, shower curtain, box, whiteboard, person, nightstand, toilet, sink\n",
        ", lamp, bathtub, bag\"\"\"\n",
        "category = category.split(r', ')\n",
        "category = [i.replace('\\n','') for i in category]\n",
        "category_1 = ['background']\n",
        "for categ in category:category_1.append(categ) \n",
        "print(category_1)\n",
        "category_dict = {k:category_1.index(k) for k in category_1}\n",
        "print(category_dict)\n",
        "reverse_map={i:k for k,i in category_dict.items()}\n",
        "color_list=['gray','red','green','#FFFF00','#8c564b','#4B8BBE','#306998','#FFE873','#FFD43B','#646464','#5a0000','#003a27','#C0C0C0','#808080','#800000','#808000','#00FF00','#00FFFF','#008080','#000080','#FF00FF','#800080','#CD5C5C','#F08080','#FA8072','#E9967A','#FFA07A','#DC143C','#FF7F50','#FFD700','#ffffe0','#bdb76b','#228b22','#B0E0E6','#4169e1','#f0ffff','#d2691e','#BC8F8F']\n",
        "class_color_map={k:color_list[i] for i,k in enumerate(reverse_map.keys())}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['background', 'wall', 'floor', 'cabinet', 'bed', 'chair', 'sofa', 'table', 'door', 'window', 'bookshelf', 'picture', 'counter', 'blinds', 'desk', 'shelves', 'curtain', 'dresser', 'pillow', 'mirror', 'floor mat', 'clothes', 'ceiling', 'books', 'fridge', 'tv', 'paper', 'towel', 'shower curtain', 'box', 'whiteboard', 'person', 'nightstand', 'toilet', 'sink', 'lamp', 'bathtub', 'bag']\n",
            "{'background': 0, 'wall': 1, 'floor': 2, 'cabinet': 3, 'bed': 4, 'chair': 5, 'sofa': 6, 'table': 7, 'door': 8, 'window': 9, 'bookshelf': 10, 'picture': 11, 'counter': 12, 'blinds': 13, 'desk': 14, 'shelves': 15, 'curtain': 16, 'dresser': 17, 'pillow': 18, 'mirror': 19, 'floor mat': 20, 'clothes': 21, 'ceiling': 22, 'books': 23, 'fridge': 24, 'tv': 25, 'paper': 26, 'towel': 27, 'shower curtain': 28, 'box': 29, 'whiteboard': 30, 'person': 31, 'nightstand': 32, 'toilet': 33, 'sink': 34, 'lamp': 35, 'bathtub': 36, 'bag': 37}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH44_RJvK9TL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb01001d-487c-44aa-a535-d1aa1f6b24cb"
      },
      "source": [
        "\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "Image_width = 640 \n",
        "Image_height = 480 \n",
        "no_classes = len(category_dict)\n",
        "def load_data(path, split=0.2):\n",
        "    images = sorted(glob.glob(os.path.join(path, \"image/*\")))\n",
        "    print(len(images))\n",
        "    masks = sorted(glob.glob(os.path.join(path, \"mask/*\")))\n",
        "    print(len(masks))\n",
        "    total_size = 7990\n",
        "    test_size = 1990\n",
        "    valid_size=1000\n",
        "    training_x, test_x = train_test_split(images[:7990], test_size=test_size, random_state=42)\n",
        "    training_y, test_y = train_test_split(masks[:7990], test_size=test_size, random_state=42)\n",
        "    train_x, valid_x = train_test_split(training_x, test_size=valid_size, random_state=42)\n",
        "    train_y, valid_y = train_test_split(training_y, test_size=valid_size, random_state=42)\n",
        "    return (train_x, train_y), (valid_x, valid_y),(test_x, test_y)\n",
        "(train_x,train_y),(valid_x,valid_y),(test_x, test_y)=load_data('/content/drive/MyDrive/depth')\n",
        "train_size=len(train_x)\n",
        "valid_size=len(valid_x)\n",
        "\n",
        "def read_image(path):\n",
        "    path = path.decode()\n",
        "    x = cv.imread(path, cv.IMREAD_COLOR)\n",
        "    x = cv.resize(x,(640,480),interpolation=cv.INTER_AREA)\n",
        "    x = x/255.0\n",
        "    x=tf.cast(x,dtype=tf.float32)\n",
        "    return x\n",
        "\n",
        "def read_mask(path):\n",
        "    path = path.decode()\n",
        "    x = cv.imread(path, cv.IMREAD_GRAYSCALE)\n",
        "    x = cv.resize(x,(640,480),interpolation=cv.INTER_NEAREST)\n",
        "  \n",
        "    x = to_categorical(x,num_classes=no_classes)\n",
        "    x = x[:,:,:]\n",
        "    # x = np.expand_dims(x, axis=-1)\n",
        "    # x=np.concatenate([x,x],axis=-1)\n",
        "    x=tf.cast(x,dtype=tf.float32)\n",
        "    return x\n",
        "# read_mask('/content/drive/MyDrive/depth/mask100/mask1.png')\n",
        "def parser(x,y):\n",
        "    def _parse(x,y):\n",
        "        x=read_image(x)\n",
        "        y=read_mask(y)\n",
        "        return x,y\n",
        "    x,y = tf.numpy_function(_parse, [x,y], [tf.float32,tf.float32])\n",
        "    x.set_shape([Image_height, Image_width, 3])\n",
        "    y.set_shape([Image_height, Image_width, no_classes])\n",
        "    return x,y\n",
        "    \n",
        "def tf_dataset(x, y, batch):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "    dataset = dataset.map(parser)\n",
        "    # dataset = dataset.cache()\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.batch(batch)\n",
        "    dataset = dataset.prefetch(AUTO)\n",
        "    return dataset\n",
        "train_dataset=tf_dataset(train_x,train_y,batch=12)\n",
        "valid_dataset=tf_dataset(valid_x,valid_y,batch=12)\n",
        "valid_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8033\n",
            "7990\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None, 480, 640, 3), (None, 480, 640, 38)), types: (tf.float32, tf.float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlufJvHAlU4M",
        "outputId": "62426928-7afb-4806-8c64-9c1cfa690d8e"
      },
      "source": [
        "print(test_x[:100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/drive/MyDrive/depth/image/image5457.jpg', '/content/drive/MyDrive/depth/image/image5917.jpg', '/content/drive/MyDrive/depth/image/image7738.jpg', '/content/drive/MyDrive/depth/image/image7847.jpg', '/content/drive/MyDrive/depth/image/image3387.jpg', '/content/drive/MyDrive/depth/image/image516.jpg', '/content/drive/MyDrive/depth/image/image1978.jpg', '/content/drive/MyDrive/depth/image/image4452.jpg', '/content/drive/MyDrive/depth/image/image470.jpg', '/content/drive/MyDrive/depth/image/image2603.jpg', '/content/drive/MyDrive/depth/image/image3895.jpg', '/content/drive/MyDrive/depth/image/image5776.jpg', '/content/drive/MyDrive/depth/image/image164.jpg', '/content/drive/MyDrive/depth/image/image7588.jpg', '/content/drive/MyDrive/depth/image/image5720.jpg', '/content/drive/MyDrive/depth/image/image2827.jpg', '/content/drive/MyDrive/depth/image/image1903.jpg', '/content/drive/MyDrive/depth/image/image5203.jpg', '/content/drive/MyDrive/depth/image/image2773.jpg', '/content/drive/MyDrive/depth/image/image1729.jpg', '/content/drive/MyDrive/depth/image/image2831.jpg', '/content/drive/MyDrive/depth/image/image4291.jpg', '/content/drive/MyDrive/depth/image/image1213.jpg', '/content/drive/MyDrive/depth/image/image7546.jpg', '/content/drive/MyDrive/depth/image/image249.jpg', '/content/drive/MyDrive/depth/image/image429.jpg', '/content/drive/MyDrive/depth/image/image2278.jpg', '/content/drive/MyDrive/depth/image/image7784.jpg', '/content/drive/MyDrive/depth/image/image5716.jpg', '/content/drive/MyDrive/depth/image/image3109.jpg', '/content/drive/MyDrive/depth/image/image4577.jpg', '/content/drive/MyDrive/depth/image/image2260.jpg', '/content/drive/MyDrive/depth/image/image1661.jpg', '/content/drive/MyDrive/depth/image/image2164.jpg', '/content/drive/MyDrive/depth/image/image48.jpg', '/content/drive/MyDrive/depth/image/image2817.jpg', '/content/drive/MyDrive/depth/image/image2400.jpg', '/content/drive/MyDrive/depth/image/image1285.jpg', '/content/drive/MyDrive/depth/image/image1954.jpg', '/content/drive/MyDrive/depth/image/image3078.jpg', '/content/drive/MyDrive/depth/image/image1923.jpg', '/content/drive/MyDrive/depth/image/image141.jpg', '/content/drive/MyDrive/depth/image/image1235.jpg', '/content/drive/MyDrive/depth/image/image7963.jpg', '/content/drive/MyDrive/depth/image/image3071.jpg', '/content/drive/MyDrive/depth/image/image7259.jpg', '/content/drive/MyDrive/depth/image/image3418.jpg', '/content/drive/MyDrive/depth/image/image1199.jpg', '/content/drive/MyDrive/depth/image/image7328.jpg', '/content/drive/MyDrive/depth/image/image4750.jpg', '/content/drive/MyDrive/depth/image/image1286.jpg', '/content/drive/MyDrive/depth/image/image7629.jpg', '/content/drive/MyDrive/depth/image/image4930.jpg', '/content/drive/MyDrive/depth/image/image1907.jpg', '/content/drive/MyDrive/depth/image/image2053.jpg', '/content/drive/MyDrive/depth/image/image1465.jpg', '/content/drive/MyDrive/depth/image/image4490.jpg', '/content/drive/MyDrive/depth/image/image4884.jpg', '/content/drive/MyDrive/depth/image/image7101.jpg', '/content/drive/MyDrive/depth/image/image949.jpg', '/content/drive/MyDrive/depth/image/image889.jpg', '/content/drive/MyDrive/depth/image/image7615.jpg', '/content/drive/MyDrive/depth/image/image6905.jpg', '/content/drive/MyDrive/depth/image/image4475.jpg', '/content/drive/MyDrive/depth/image/image7420.jpg', '/content/drive/MyDrive/depth/image/image2072.jpg', '/content/drive/MyDrive/depth/image/image2401.jpg', '/content/drive/MyDrive/depth/image/image4131.jpg', '/content/drive/MyDrive/depth/image/image5407.jpg', '/content/drive/MyDrive/depth/image/image3231.jpg', '/content/drive/MyDrive/depth/image/image4194.jpg', '/content/drive/MyDrive/depth/image/image2947.jpg', '/content/drive/MyDrive/depth/image/image4459.jpg', '/content/drive/MyDrive/depth/image/image2558.jpg', '/content/drive/MyDrive/depth/image/image4706.jpg', '/content/drive/MyDrive/depth/image/image7327.jpg', '/content/drive/MyDrive/depth/image/image1921.jpg', '/content/drive/MyDrive/depth/image/image5978.jpg', '/content/drive/MyDrive/depth/image/image2330.jpg', '/content/drive/MyDrive/depth/image/image7428.jpg', '/content/drive/MyDrive/depth/image/image4878.jpg', '/content/drive/MyDrive/depth/image/image5983.jpg', '/content/drive/MyDrive/depth/image/image3002.jpg', '/content/drive/MyDrive/depth/image/image2780.jpg', '/content/drive/MyDrive/depth/image/image7681.jpg', '/content/drive/MyDrive/depth/image/image7383.jpg', '/content/drive/MyDrive/depth/image/image2913.jpg', '/content/drive/MyDrive/depth/image/image3217.jpg', '/content/drive/MyDrive/depth/image/image7280.jpg', '/content/drive/MyDrive/depth/image/image1312.jpg', '/content/drive/MyDrive/depth/image/image6673.jpg', '/content/drive/MyDrive/depth/image/image452.jpg', '/content/drive/MyDrive/depth/image/image3972.jpg', '/content/drive/MyDrive/depth/image/image3340.jpg', '/content/drive/MyDrive/depth/image/image5157.jpg', '/content/drive/MyDrive/depth/image/image3790.jpg', '/content/drive/MyDrive/depth/image/image6024.jpg', '/content/drive/MyDrive/depth/image/image3771.jpg', '/content/drive/MyDrive/depth/image/image5392.jpg', '/content/drive/MyDrive/depth/image/image7628.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOTZSsCjlUf4"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGHr-V6pFCFw"
      },
      "source": [
        "#changes \n",
        "#Added a extra convolution in the encoder part lets look if it makes improvement or not \n",
        "def squeeze_excite_block(inputs, ratio=8):\n",
        "    init = inputs\n",
        "    channel_axis = -1\n",
        "    filters = init.shape[channel_axis]\n",
        "    se_shape = (1, 1, filters)\n",
        "\n",
        "    se = GlobalAveragePooling2D()(init)\n",
        "    se = Reshape(se_shape)(se)\n",
        "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "\n",
        "    x = multiply([init, se])\n",
        "    return x\n",
        "def encoder_conv_block(inputs,filters):\n",
        "  x = Conv2D(filters, (3, 3), padding=\"same\",kernel_initializer='he_normal')(inputs)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU(alpha=0.001)(x)\n",
        "  x = Conv2D(filters, (3, 3), padding=\"same\",kernel_initializer='he_normal')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU(alpha=0.001)(x)\n",
        "  return x \n",
        "def decoder_conv_block(inputs,filters,filters2):\n",
        "  x = Conv2D(filters, (3, 3), padding=\"same\",kernel_initializer='he_normal')(inputs)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU(alpha=0.001)(x)\n",
        "  x = Conv2D(filters2, (3, 3), padding=\"same\",kernel_initializer='he_normal')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU(alpha=0.001)(x)\n",
        "  return x\n",
        "\n",
        "def encoder(inputs):\n",
        "  num_filters = [64,128,256,256,512]\n",
        "  x= inputs\n",
        "  for i,filters  in enumerate(num_filters):\n",
        "    x = encoder_conv_block(x,filters)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "  return x \n",
        "def decoder(x):\n",
        "  num_filters = [64,128, 256,256,512,512]\n",
        "  num_filters.reverse()\n",
        "  for i in range(len(num_filters)-1):\n",
        "    x = decoder_conv_block(x,num_filters[i],num_filters[i+1])\n",
        "    x = UpSampling2D((2,2))(x)\n",
        "    \n",
        "  return x\n",
        "def output_block(inputs,classes):\n",
        "    x = Conv2D(classes,(1, 1), padding=\"same\")(inputs)\n",
        "    return x\n",
        "def main_model(shape):\n",
        "  inputs = Input(shape)\n",
        "  encoded = encoder(inputs)\n",
        "  decoded = decoder(encoded)\n",
        "  output = output_block(decoded,classes=38)\n",
        "  model = Model(inputs,output)\n",
        "  return model\n",
        "\n",
        "model = main_model((480,640,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5OPWbZNKuPM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9179dee4-f1b7-4aca-acf2-5c974990b09e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 480, 640, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 480, 640, 64)      1792      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 480, 640, 64)      256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 480, 640, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 480, 640, 64)      36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 480, 640, 64)      256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 480, 640, 64)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 240, 320, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 240, 320, 128)     73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 240, 320, 128)     512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 240, 320, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 240, 320, 128)     147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 240, 320, 128)     512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 240, 320, 128)     0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 120, 160, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 120, 160, 256)     295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 120, 160, 256)     1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 120, 160, 256)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 120, 160, 256)     590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 120, 160, 256)     1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 120, 160, 256)     0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 60, 80, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 60, 80, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 60, 80, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 60, 80, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 60, 80, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 60, 80, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 60, 80, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 30, 40, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 30, 40, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 30, 40, 512)       2048      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 30, 40, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 30, 40, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 30, 40, 512)       2048      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 30, 40, 512)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 15, 20, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 15, 20, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 15, 20, 512)       2048      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)   (None, 15, 20, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 15, 20, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 15, 20, 512)       2048      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)   (None, 15, 20, 512)       0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d (UpSampling2D) (None, 30, 40, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 30, 40, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 30, 40, 512)       2048      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)   (None, 30, 40, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 30, 40, 256)       1179904   \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 30, 40, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)   (None, 30, 40, 256)       0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 60, 80, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 60, 80, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 60, 80, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)   (None, 60, 80, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 60, 80, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 60, 80, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)   (None, 60, 80, 256)       0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2 (None, 120, 160, 256)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 120, 160, 256)     590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 120, 160, 256)     1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)   (None, 120, 160, 256)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 120, 160, 128)     295040    \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 120, 160, 128)     512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)   (None, 120, 160, 128)     0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2 (None, 240, 320, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 240, 320, 128)     147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 240, 320, 128)     512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)   (None, 240, 320, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 240, 320, 64)      73792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 240, 320, 64)      256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_19 (LeakyReLU)   (None, 240, 320, 64)      0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2 (None, 480, 640, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 480, 640, 38)      2470      \n",
            "=================================================================\n",
            "Total params: 16,435,238\n",
            "Trainable params: 16,424,614\n",
            "Non-trainable params: 10,624\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaSnZSXvyIj0"
      },
      "source": [
        "#june 18 5000 with an additional conv layer ..faster but not more accurate i guess"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzHtdx6wNevn"
      },
      "source": [
        "#loss function \n",
        "\n",
        "import gc \n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import CSVLogger ,LearningRateScheduler,Callback\n",
        "class ClearMemory(Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch%1==0:\n",
        "            v_steps=valid_size//16\n",
        "            loss = model.evaluate(valid_dataset,steps=v_steps)\n",
        "            logs['val_loss'] = loss[0]\n",
        "            logs['val_custom_metrics'] = loss[1]\n",
        "            gc.collect()\n",
        "            tf.keras.backend.clear_session()\n",
        "            tf.compat.v1.reset_default_graph() \n",
        "        gc.collect()\n",
        "        tf.keras.backend.clear_session()\n",
        "        tf.compat.v1.reset_default_graph() \n",
        "        return\n",
        "    # def on_train_batch_end(self,batch,logs=None):\n",
        "    #     print('memory usesd: ' + str(psutil.virtual_memory().used // 1e6)) \n",
        "\n",
        "filepath= '/content/drive/MyDrive/training-daily/july19-5000-more-filters/checkpoint/'\n",
        "directory= filepath\n",
        "# if not os.path.exists(directory):\n",
        "#     os.makedirs(directory)\n",
        "callbacks = [\n",
        "    ClearMemory(),   \n",
        "    EarlyStopping(monitor='val_custom_metrics', patience=3),\n",
        "    ModelCheckpoint(filepath, monitor='val_custom_metrics',verbose=1,mode='max',save_best_only=True),\n",
        "    # LearningRateScheduler(lrfn, verbose = True)\n",
        "    \n",
        "]\n",
        "# loss = tf.keras.losses.categorical_crossentropy(from_logits=True)\n",
        "def binary_loss(y_true, y_pred):\n",
        "    loss = binary_crossentropy(y_true, y_pred,from_logits=True)\n",
        "    loss_value = tf.math.reduce_mean(loss,axis=[0])\n",
        "    return loss_value\n",
        "# loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True, )\n",
        "# def cross_entropy_loss(y_true,y_pred):\n",
        "#     return loss(y_true,y_pred)\n",
        "def cross_entropy_loss(y_true,y_pred):\n",
        "    loss = tf.nn.softmax_cross_entropy_with_logits(\n",
        "    y_true, y_pred, axis=-1, name=None)\n",
        "    return loss\n",
        "\n",
        "def custom_metrics(y_true,y_pred,smooth=1):\n",
        "    y_pred = tf.math.argmax(y_pred, axis=-1)\n",
        "    # y_pred = tf.expand_dims(y_pred,axis=-1)\n",
        "    y_pred = tf.one_hot(y_pred,38)\n",
        "    y_true = y_true[:,:,:,1:38]\n",
        "    y_pred= y_pred[:,:,:,1:38]\n",
        "    intersection  = tf.math.reduce_sum((y_true*y_pred),axis = [1,2,3])\n",
        "    union = (tf.math.reduce_sum(y_true,axis=[1,2,3])+tf.math.reduce_sum(y_pred,axis = [1,2,3])) - intersection\n",
        "    return tf.math.reduce_mean((intersection+smooth)/(union+smooth),axis=0)\n",
        "smooth = 1\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true = tf.keras.layers.Flatten()(y_true)\n",
        "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
        "model=tf.keras.models.load_model('/content/drive/MyDrive/training-daily/july19-5000-more-filters/checkpoint/',custom_objects={\n",
        "        'cross_entropy_loss': cross_entropy_loss ,'dice_coef': dice_coef,'custom_metrics':custom_metrics})\n",
        "model.compile(loss = cross_entropy_loss,optimizer=Adam(learning_rate =.001),metrics=[custom_metrics])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "id6vh8YpLOc0"
      },
      "source": [
        "# epoch=[1,2,3,4]\n",
        "# t_steps=train_size//16\n",
        "# for i in epoch:\n",
        "#   model.fit(train_dataset,epochs=i,initial_epoch=i-1,steps_per_epoch=t_steps,callbacks=callbacks)\n",
        "#   tf.keras.backend.clear_session()\n",
        "#   gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOu4GKVVOpis",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "outputId": "7d17fa4d-1c96-4c07-ab95-72e2a384cbb2"
      },
      "source": [
        "# %%file mprun_demo.py\n",
        "def train(epoch):\n",
        "    t_steps=train_size//12\n",
        "    v_steps=valid_size//12\n",
        "    model.fit(train_dataset, \n",
        "                            epochs =epoch ,\n",
        "                            steps_per_epoch = t_steps,\n",
        "                            callbacks=callbacks)\n",
        "    \n",
        "train(8)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "416/416 [==============================] - 942s 2s/step - loss: 1.4299 - custom_metrics: 0.3684\n",
            "62/62 [==============================] - 70s 1s/step - loss: 1.6110 - custom_metrics: 0.3476\n",
            "\n",
            "Epoch 00001: val_custom_metrics improved from -inf to 0.34765, saving model to /content/drive/MyDrive/training-daily/july19-5000-more-filters/checkpoint/\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/training-daily/july19-5000-more-filters/checkpoint/assets\n",
            "Epoch 2/8\n",
            "416/416 [==============================] - 796s 2s/step - loss: 1.3901 - custom_metrics: 0.3815\n",
            "62/62 [==============================] - 70s 1s/step - loss: 1.6554 - custom_metrics: 0.3408\n",
            "\n",
            "Epoch 00002: val_custom_metrics did not improve from 0.34765\n",
            "Epoch 3/8\n",
            "416/416 [==============================] - 795s 2s/step - loss: 1.3535 - custom_metrics: 0.3925\n",
            "62/62 [==============================] - 72s 1s/step - loss: 1.7234 - custom_metrics: 0.3296\n",
            "\n",
            "Epoch 00003: val_custom_metrics did not improve from 0.34765\n",
            "Epoch 4/8\n",
            " 29/416 [=>............................] - ETA: 11:38 - loss: 1.3279 - custom_metrics: 0.4059"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-3ecf3cbec9b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                             callbacks=callbacks)\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-3ecf3cbec9b9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      6\u001b[0m                             \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                             \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8YPykz0GFDX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5n5u2rNt6uR"
      },
      "source": [
        "model = main_model((480,640,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJYCUWEPhhIW"
      },
      "source": [
        "optimizer = Adam(learning_rate=.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5l4dX3mcuqB"
      },
      "source": [
        "@tf.function\n",
        "def train_step(x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model(x, training=True)\n",
        "        loss_value = (cross_entropy_loss(y, logits))\n",
        "    # loss_value =tf.math.reduce_mean(loss_value,axis=[0,1,2])\n",
        "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    train_acc_metrics =  custom_metrics(y, logits)\n",
        "    return loss_value,train_acc_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvyT2NkxcwSN"
      },
      "source": [
        "@tf.function\n",
        "def test_step(x, y):\n",
        "    val_logits = model(x, training=False)\n",
        "    val_acc_metric = (y, val_logits)\n",
        "    val_loss = cross_entropy_loss(u,val_logits)\n",
        "    return val_acc_metric,val_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASeFqZ_DdAwj"
      },
      "source": [
        "# import time\n",
        "# epochs = 4\n",
        "# batch_size = 16\n",
        "# for epoch in range(epochs):\n",
        "#     print(\"\\nStart of epoch %d\", (epoch))\n",
        "#     start_time = time.time()\n",
        "#     for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "#         loss_value,loss_metrics = train_step(x_batch_train, y_batch_train)\n",
        "#         print(step, loss_value,loss_metrics)\n",
        "#         print(\"Seen so far: samples\", (step + 1))\n",
        "#     # print(\"Training acc over epoch: %.4f\" train_acc)\n",
        "#     val_losses = 0\n",
        "#     val_metrics=0\n",
        "#     for val_steps,(x_batch_val, y_batch_val) in enumerate(valid_dataset):\n",
        "#         val_metic,val_loss = test_step(x_batch_val, y_batch_val)\n",
        "#         val_losses +=val_loss\n",
        "#         val_metrics +=val_metric\n",
        "#     print(\"Validation loss: %.4f\",(val_losses/val_steps))\n",
        "#     print('validation custom metrics',val_metrics/val_steps)\n",
        "#     print(\"Time taken: %.2fs\" % (time.time() - start_time))\n",
        "#     gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8GwH6gcPnRZ"
      },
      "source": [
        "def read_image(path):\n",
        "    x = cv.imread(path, cv.IMREAD_COLOR)\n",
        "    x = cv.resize(x,(640,480),interpolation=cv.INTER_AREA)\n",
        "    x = x/255.0\n",
        "    x=tf.cast(x,dtype=tf.float32)\n",
        "    return x\n",
        "\n",
        "def read_mask(path):\n",
        "    x = cv.imread(path, cv.IMREAD_GRAYSCALE)\n",
        "    x = cv.resize(x,(640,480),interpolation=cv.INTER_AREA)\n",
        "    x = to_categorical(x,num_classes=no_classes+1)\n",
        "    x = x[:,:,:]\n",
        "    # x = np.expand_dims(x, axis=-1)\n",
        "    # x=np.concatenate([x,x],axis=-1)\n",
        "    x=tf.cast(x,dtype=tf.float32)\n",
        "    return x\n",
        "def custom_metrics(y_true,y_pred,smooth=1):\n",
        "    y_pred = tf.math.argmax(y_pred, axis=-1)\n",
        "    # y_pred = tf.expand_dims(y_pred,axis=-1)\n",
        "    y_pred = tf.one_hot(y_pred,38)\n",
        "    y_true = y_true[:,:,:,1:38]\n",
        "    y_pred= y_pred[:,:,:,1:38]\n",
        "    intersection  = tf.math.reduce_sum((y_true*y_pred),axis = [1,2,3])\n",
        "    union = tf.math.reduce_sum(y_true,axis=[1,2,3])+tf.math.reduce_sum(y_pred,axis = [1,2,3]) - intersection \n",
        "    return tf.math.reduce_mean((intersection+smooth)/(union+smooth),axis=0)\n",
        "def load_data(images,masks):\n",
        "    length = 1990\n",
        "    iou=0\n",
        "    for i,(image,mask) in enumerate(zip(images,masks)):\n",
        "    \n",
        "      img = read_image(image)\n",
        "      mas = read_mask(mask)\n",
        "      img = np.expand_dims(img,0)\n",
        "      mas = np.expand_dims(mas,0)\n",
        "      prediction = model.predict(img)\n",
        "      iou += custom_metrics(mas,prediction)\n",
        "      print(i,iou)\n",
        "    return iou/length\n",
        "no_classes=37\n",
        "print(len(test_x))\n",
        "x=load_data(test_x,test_y)\n",
        "print('*****************************************************************************************************************')\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXH9XLBMM2bB"
      },
      "source": [
        "model2 = main_model2(shape,no_classes)\n",
        "model2=tf.keras.models.load_model(filepath2,custom_objects={'cross_entropy_loss':cross_entropy_loss,'dice_coef':dice_coef,'custom_metrics':custom_metrics})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-gQ6TBDMf4B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZsGANPHM1T5"
      },
      "source": [
        "import matplotlib\n",
        "cmap = matplotlib.colors.ListedColormap(color_list)\n",
        "def plot(image,numpy,prediction):\n",
        "    plt.figure(figsize=(14,14))\n",
        "    plt.subplot(131)\n",
        "    plt.imshow(np.squeeze(prediction)+1,cmap=cmap,vmin=1, vmax=len(color_list))\n",
        "    plt.subplot(132)\n",
        "    plt.imshow(image)\n",
        "    plt.subplot(133)\n",
        "    plt.imshow(numpy,cmap='gray')\n",
        "    print(prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irZ0RNFNVg5q"
      },
      "source": [
        "import matplotlib\n",
        "def plot(image,numpy,prediction):\n",
        "    plt.figure(figsize=(14,14))\n",
        "    plt.subplot(131)\n",
        "    plt.imshow(np.squeeze(prediction),cmap=plt.get_cmap('gray'))\n",
        "    plt.subplot(132)\n",
        "    plt.imshow(image)\n",
        "    plt.subplot(133)\n",
        "    plt.imshow(numpy,cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiDguJ9C-6Pg"
      },
      "source": [
        "def prediction(path):\n",
        "    image = cv.imread(path,cv.IMREAD_COLOR)\n",
        "    x = cv.resize(image,(640,480),interpolation=cv.INTER_NEAREST)\n",
        "    x = x/255.0\n",
        "    x=np.expand_dims(x,0)\n",
        "    y = model.predict(x)\n",
        "    print(y.shape)\n",
        "    numpy = np.zeros((y.shape[1],y.shape[2],y.shape[3]))\n",
        "    print(numpy.shape)\n",
        "    numpy[:,:,:] = y \n",
        "    prediction= numpy.argmax(axis=-1)\n",
        "    print(prediction.shape)\n",
        "    numpy= tf.one_hot(prediction,38)\n",
        "    plot(image,numpy[:,:,2],prediction)\n",
        "    return numpy\n",
        "path = '/content/drive/MyDrive/depth/image/image1.jpg'\n",
        "prediction1=prediction(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb2AVBOiBwYB"
      },
      "source": [
        "for i in range(prediction1.shape[2]):\n",
        "    # for j in range(prediction1.shape[1]):\n",
        "    #     # if prediction1[i,j]>2:\n",
        "    (prediction1.shape)\n",
        "    print(prediction1[])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZIgQWQFHcr7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}