{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled121june19-skip_multiply.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sameepshrestha/segmentation_state_of_the_art/blob/main/Untitled121june19_skip_multiply.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kTMpcSd1YrH"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPSbYPZyCIvP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d46d7614-8b3d-43ef-e7a7-df1d9bb1c720"
      },
      "source": [
        "# model.summary()\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXMEt7jkCaVW"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "import numpy as np \n",
        "import cv2 as cv \n",
        "from PIL import Image, ImageDraw\n",
        "import json \n",
        "import os \n",
        "import glob \n",
        "import re \n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf \n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Reshape, Concatenate,MaxPooling2D, AveragePooling2D,Input, BatchNormalization, Activation, UpSampling2D, Concatenate, LeakyReLU,Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D,Multiply\n",
        "from tensorflow.keras.optimizers import Adam \n",
        "#using tensorflow backend 16 so keras backend still 32bytes so no keras to be used\n",
        "# from keras.layers.merge import concatenate,Concatenate\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gc\n",
        "import psutil"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_maY0bRpS38"
      },
      "source": [
        "import math\n",
        "import sys, time\n",
        "\n",
        "# Interpolation kernel\n",
        "def u(s,a):\n",
        "    if (abs(s) >=0) & (abs(s) <=1):\n",
        "        return (a+2)*(abs(s)**3)-(a+3)*(abs(s)**2)+1\n",
        "    elif (abs(s) > 1) & (abs(s) <= 2):\n",
        "        return a*(abs(s)**3)-(5*a)*(abs(s)**2)+(8*a)*abs(s)-4*a\n",
        "    return 0\n",
        "\n",
        "#Paddnig\n",
        "def padding(img,H,W,C):\n",
        "    zimg = np.zeros((H+4,W+4,C))\n",
        "    zimg[2:H+2,2:W+2,:C] = img\n",
        "    zimg[2:H+2,0:2,:C]=img[:,0:1,:C]\n",
        "    zimg[H+2:H+4,2:W+2,:]=img[H-1:H,:,:]\n",
        "    zimg[2:H+2,W+2:W+4,:]=img[:,W-1:W,:]\n",
        "    zimg[0:2,2:W+2,:C]=img[0:1,:,:C]\n",
        "    zimg[0:2,0:2,:C]=img[0,0,:C]\n",
        "    zimg[H+2:H+4,0:2,:C]=img[H-1,0,:C]\n",
        "    zimg[H+2:H+4,W+2:W+4,:C]=img[H-1,W-1,:C]\n",
        "    zimg[0:2,W+2:W+4,:C]=img[0,W-1,:C]\n",
        "    return zimg\n",
        "\n",
        "# https://github.com/rootpine\n",
        "# Bicubic operation\n",
        "def UPsampling_cubic(img, ratio, a):\n",
        "    #Get image size\n",
        "    H,W,C = img.shape\n",
        "\n",
        "    img = padding(img,H,W,C)\n",
        "    #Create new image\n",
        "    dH = math.floor(H*ratio)\n",
        "    dW = math.floor(W*ratio)\n",
        "    dst = np.zeros((dH, dW, 3))\n",
        "\n",
        "    h = 1/ratio\n",
        "\n",
        "    print('Start bicubic interpolation')\n",
        "    print('It will take a little while...')\n",
        "    inc = 0\n",
        "    for c in range(C):\n",
        "        for j in range(dH):\n",
        "            for i in range(dW):\n",
        "                x, y = i * h + 2 , j * h + 2\n",
        "\n",
        "                x1 = 1 + x - math.floor(x)\n",
        "                x2 = x - math.floor(x)\n",
        "                x3 = math.floor(x) + 1 - x\n",
        "                x4 = math.floor(x) + 2 - x\n",
        "\n",
        "                y1 = 1 + y - math.floor(y)\n",
        "                y2 = y - math.floor(y)\n",
        "                y3 = math.floor(y) + 1 - y\n",
        "                y4 = math.floor(y) + 2 - y\n",
        "\n",
        "                mat_l = np.matrix([[u(x1,a),u(x2,a),u(x3,a),u(x4,a)]])\n",
        "                mat_m = np.matrix([[img[int(y-y1),int(x-x1),c],img[int(y-y2),int(x-x1),c],img[int(y+y3),int(x-x1),c],img[int(y+y4),int(x-x1),c]],\n",
        "                                   [img[int(y-y1),int(x-x2),c],img[int(y-y2),int(x-x2),c],img[int(y+y3),int(x-x2),c],img[int(y+y4),int(x-x2),c]],\n",
        "                                   [img[int(y-y1),int(x+x3),c],img[int(y-y2),int(x+x3),c],img[int(y+y3),int(x+x3),c],img[int(y+y4),int(x+x3),c]],\n",
        "                                   [img[int(y-y1),int(x+x4),c],img[int(y-y2),int(x+x4),c],img[int(y+y3),int(x+x4),c],img[int(y+y4),int(x+x4),c]]])\n",
        "                mat_r = np.matrix([[u(y1,a)],[u(y2,a)],[u(y3,a)],[u(y4,a)]])\n",
        "                dst[j, i, c] = np.dot(np.dot(mat_l, mat_m),mat_r)\n",
        "    return dst\n",
        "\n",
        "# Read image\n",
        "img = cv.imread('butterfly.png')\n",
        "\n",
        "# Scale factor\n",
        "ratio = 2\n",
        "# Coefficient\n",
        "a = -1/2\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jYMHKtEL-oK"
      },
      "source": [
        "tf.keras.mixed_precision.experimental.set_policy('mixed_float16')\n",
        "# # tf.compat.v1.disable_eager_execution()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Jl9K0TuK0kZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91936f82-8af4-4198-865d-935b48ed21f6"
      },
      "source": [
        "category = \"\"\"wall, floor, cabinet, bed, chair, sofa, table, door, window, bookshelf, picture, counter, blinds, desk, shelves, curtain, dresser\n",
        ", pillow, mirror, floor mat, clothes, ceiling, books, fridge, tv, paper, towel, shower curtain, box, whiteboard, person, nightstand, toilet, sink\n",
        ", lamp, bathtub, bag\"\"\"\n",
        "category = category.split(r', ')\n",
        "category = [i.replace('\\n','') for i in category]\n",
        "category_1 = ['background']\n",
        "for categ in category:category_1.append(categ) \n",
        "print(category_1)\n",
        "category_dict = {k:category_1.index(k) for k in category_1}\n",
        "print(category_dict)\n",
        "reverse_map={i:k for k,i in category_dict.items()}\n",
        "color_list=['gray','red','green','#FFFF00','#8c564b','#4B8BBE','#306998','#FFE873','#FFD43B','#646464','#5a0000','#003a27','#C0C0C0','#808080','#800000','#808000','#00FF00','#00FFFF','#008080','#000080','#FF00FF','#800080','#CD5C5C','#F08080','#FA8072','#E9967A','#FFA07A','#DC143C','#FF7F50','#FFD700','#ffffe0','#bdb76b','#228b22','#B0E0E6','#4169e1','#f0ffff','#d2691e','#BC8F8F']\n",
        "class_color_map={k:color_list[i] for i,k in enumerate(reverse_map.keys())}"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['background', 'wall', 'floor', 'cabinet', 'bed', 'chair', 'sofa', 'table', 'door', 'window', 'bookshelf', 'picture', 'counter', 'blinds', 'desk', 'shelves', 'curtain', 'dresser', 'pillow', 'mirror', 'floor mat', 'clothes', 'ceiling', 'books', 'fridge', 'tv', 'paper', 'towel', 'shower curtain', 'box', 'whiteboard', 'person', 'nightstand', 'toilet', 'sink', 'lamp', 'bathtub', 'bag']\n",
            "{'background': 0, 'wall': 1, 'floor': 2, 'cabinet': 3, 'bed': 4, 'chair': 5, 'sofa': 6, 'table': 7, 'door': 8, 'window': 9, 'bookshelf': 10, 'picture': 11, 'counter': 12, 'blinds': 13, 'desk': 14, 'shelves': 15, 'curtain': 16, 'dresser': 17, 'pillow': 18, 'mirror': 19, 'floor mat': 20, 'clothes': 21, 'ceiling': 22, 'books': 23, 'fridge': 24, 'tv': 25, 'paper': 26, 'towel': 27, 'shower curtain': 28, 'box': 29, 'whiteboard': 30, 'person': 31, 'nightstand': 32, 'toilet': 33, 'sink': 34, 'lamp': 35, 'bathtub': 36, 'bag': 37}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH44_RJvK9TL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94bd60c3-b51d-40db-95d7-f2565afcd991"
      },
      "source": [
        "\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "Image_width = 640 \n",
        "Image_height = 480 \n",
        "no_classes = len(category_dict)\n",
        "def load_data(path, split=0.2):\n",
        "    images = sorted(glob.glob(os.path.join(path, \"image/*\")))\n",
        "    print(len(images))\n",
        "    masks = sorted(glob.glob(os.path.join(path, \"mask/*\")))\n",
        "    print(len(masks))\n",
        "    total_size = 7990\n",
        "    test_size = 1990\n",
        "    valid_size=1000\n",
        "    training_x, test_x = train_test_split(images[:7990], test_size=test_size, random_state=42)\n",
        "    training_y, test_y = train_test_split(masks[:7990], test_size=test_size, random_state=42)\n",
        "    train_x, valid_x = train_test_split(training_x, test_size=valid_size, random_state=42)\n",
        "    train_y, valid_y = train_test_split(training_y, test_size=valid_size, random_state=42)\n",
        "    return (train_x, train_y), (valid_x, valid_y),(test_x, test_y)\n",
        "(train_x,train_y),(valid_x,valid_y),(test_x, test_y)=load_data('/content/drive/MyDrive/depth')\n",
        "train_size=len(train_x)\n",
        "valid_size=len(valid_x)\n",
        "\n",
        "def read_image(path):\n",
        "    path = path.decode()\n",
        "    x = cv.imread(path, cv.IMREAD_COLOR)\n",
        "    x = cv.resize(x,(640,480),interpolation=cv.INTER_AREA)\n",
        "    x = x/255.0\n",
        "    x=tf.cast(x,dtype=tf.float32)\n",
        "    return x\n",
        "\n",
        "def read_mask(path):\n",
        "    path = path.decode()\n",
        "    x = cv.imread(path, cv.IMREAD_GRAYSCALE)\n",
        "    x = cv.resize(x,(640,480),interpolation=cv.INTER_NEAREST)\n",
        "  \n",
        "    x = to_categorical(x,num_classes=no_classes)\n",
        "    x = x[:,:,:]\n",
        "    # x = np.expand_dims(x, axis=-1)\n",
        "    # x=np.concatenate([x,x],axis=-1)\n",
        "    x=tf.cast(x,dtype=tf.float32)\n",
        "    return x\n",
        "# read_mask('/content/drive/MyDrive/depth/mask100/mask1.png')\n",
        "def parser(x,y):\n",
        "    def _parse(x,y):\n",
        "        x=read_image(x)\n",
        "        y=read_mask(y)\n",
        "        return x,y\n",
        "    x,y = tf.numpy_function(_parse, [x,y], [tf.float32,tf.float32])\n",
        "    x.set_shape([Image_height, Image_width, 3])\n",
        "    y.set_shape([Image_height, Image_width, no_classes])\n",
        "    return x,y\n",
        "    \n",
        "def tf_dataset(x, y, batch):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "    dataset = dataset.map(parser)\n",
        "    # dataset = dataset.cache()\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.batch(batch)\n",
        "    dataset = dataset.prefetch(AUTO)\n",
        "    return dataset\n",
        "train_dataset=tf_dataset(train_x,train_y,batch=16)\n",
        "valid_dataset=tf_dataset(valid_x,valid_y,batch=16)\n",
        "valid_dataset"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8033\n",
            "7990\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None, 480, 640, 3), (None, 480, 640, 38)), types: (tf.float32, tf.float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlufJvHAlU4M",
        "outputId": "aefce8a8-be6e-4934-8d8b-0d3be1c147f4"
      },
      "source": [
        "print(test_x[:100])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/drive/MyDrive/depth/image/image5457.jpg', '/content/drive/MyDrive/depth/image/image5917.jpg', '/content/drive/MyDrive/depth/image/image7738.jpg', '/content/drive/MyDrive/depth/image/image7847.jpg', '/content/drive/MyDrive/depth/image/image3387.jpg', '/content/drive/MyDrive/depth/image/image516.jpg', '/content/drive/MyDrive/depth/image/image1978.jpg', '/content/drive/MyDrive/depth/image/image4452.jpg', '/content/drive/MyDrive/depth/image/image470.jpg', '/content/drive/MyDrive/depth/image/image2603.jpg', '/content/drive/MyDrive/depth/image/image3895.jpg', '/content/drive/MyDrive/depth/image/image5776.jpg', '/content/drive/MyDrive/depth/image/image164.jpg', '/content/drive/MyDrive/depth/image/image7588.jpg', '/content/drive/MyDrive/depth/image/image5720.jpg', '/content/drive/MyDrive/depth/image/image2827.jpg', '/content/drive/MyDrive/depth/image/image1903.jpg', '/content/drive/MyDrive/depth/image/image5203.jpg', '/content/drive/MyDrive/depth/image/image2773.jpg', '/content/drive/MyDrive/depth/image/image1729.jpg', '/content/drive/MyDrive/depth/image/image2831.jpg', '/content/drive/MyDrive/depth/image/image4291.jpg', '/content/drive/MyDrive/depth/image/image1213.jpg', '/content/drive/MyDrive/depth/image/image7546.jpg', '/content/drive/MyDrive/depth/image/image249.jpg', '/content/drive/MyDrive/depth/image/image429.jpg', '/content/drive/MyDrive/depth/image/image2278.jpg', '/content/drive/MyDrive/depth/image/image7784.jpg', '/content/drive/MyDrive/depth/image/image5716.jpg', '/content/drive/MyDrive/depth/image/image3109.jpg', '/content/drive/MyDrive/depth/image/image4577.jpg', '/content/drive/MyDrive/depth/image/image2260.jpg', '/content/drive/MyDrive/depth/image/image1661.jpg', '/content/drive/MyDrive/depth/image/image2164.jpg', '/content/drive/MyDrive/depth/image/image48.jpg', '/content/drive/MyDrive/depth/image/image2817.jpg', '/content/drive/MyDrive/depth/image/image2400.jpg', '/content/drive/MyDrive/depth/image/image1285.jpg', '/content/drive/MyDrive/depth/image/image1954.jpg', '/content/drive/MyDrive/depth/image/image3078.jpg', '/content/drive/MyDrive/depth/image/image1923.jpg', '/content/drive/MyDrive/depth/image/image141.jpg', '/content/drive/MyDrive/depth/image/image1235.jpg', '/content/drive/MyDrive/depth/image/image7963.jpg', '/content/drive/MyDrive/depth/image/image3071.jpg', '/content/drive/MyDrive/depth/image/image7259.jpg', '/content/drive/MyDrive/depth/image/image3418.jpg', '/content/drive/MyDrive/depth/image/image1199.jpg', '/content/drive/MyDrive/depth/image/image7328.jpg', '/content/drive/MyDrive/depth/image/image4750.jpg', '/content/drive/MyDrive/depth/image/image1286.jpg', '/content/drive/MyDrive/depth/image/image7629.jpg', '/content/drive/MyDrive/depth/image/image4930.jpg', '/content/drive/MyDrive/depth/image/image1907.jpg', '/content/drive/MyDrive/depth/image/image2053.jpg', '/content/drive/MyDrive/depth/image/image1465.jpg', '/content/drive/MyDrive/depth/image/image4490.jpg', '/content/drive/MyDrive/depth/image/image4884.jpg', '/content/drive/MyDrive/depth/image/image7101.jpg', '/content/drive/MyDrive/depth/image/image949.jpg', '/content/drive/MyDrive/depth/image/image889.jpg', '/content/drive/MyDrive/depth/image/image7615.jpg', '/content/drive/MyDrive/depth/image/image6905.jpg', '/content/drive/MyDrive/depth/image/image4475.jpg', '/content/drive/MyDrive/depth/image/image7420.jpg', '/content/drive/MyDrive/depth/image/image2072.jpg', '/content/drive/MyDrive/depth/image/image2401.jpg', '/content/drive/MyDrive/depth/image/image4131.jpg', '/content/drive/MyDrive/depth/image/image5407.jpg', '/content/drive/MyDrive/depth/image/image3231.jpg', '/content/drive/MyDrive/depth/image/image4194.jpg', '/content/drive/MyDrive/depth/image/image2947.jpg', '/content/drive/MyDrive/depth/image/image4459.jpg', '/content/drive/MyDrive/depth/image/image2558.jpg', '/content/drive/MyDrive/depth/image/image4706.jpg', '/content/drive/MyDrive/depth/image/image7327.jpg', '/content/drive/MyDrive/depth/image/image1921.jpg', '/content/drive/MyDrive/depth/image/image5978.jpg', '/content/drive/MyDrive/depth/image/image2330.jpg', '/content/drive/MyDrive/depth/image/image7428.jpg', '/content/drive/MyDrive/depth/image/image4878.jpg', '/content/drive/MyDrive/depth/image/image5983.jpg', '/content/drive/MyDrive/depth/image/image3002.jpg', '/content/drive/MyDrive/depth/image/image2780.jpg', '/content/drive/MyDrive/depth/image/image7681.jpg', '/content/drive/MyDrive/depth/image/image7383.jpg', '/content/drive/MyDrive/depth/image/image2913.jpg', '/content/drive/MyDrive/depth/image/image3217.jpg', '/content/drive/MyDrive/depth/image/image7280.jpg', '/content/drive/MyDrive/depth/image/image1312.jpg', '/content/drive/MyDrive/depth/image/image6673.jpg', '/content/drive/MyDrive/depth/image/image452.jpg', '/content/drive/MyDrive/depth/image/image3972.jpg', '/content/drive/MyDrive/depth/image/image3340.jpg', '/content/drive/MyDrive/depth/image/image5157.jpg', '/content/drive/MyDrive/depth/image/image3790.jpg', '/content/drive/MyDrive/depth/image/image6024.jpg', '/content/drive/MyDrive/depth/image/image3771.jpg', '/content/drive/MyDrive/depth/image/image5392.jpg', '/content/drive/MyDrive/depth/image/image7628.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOTZSsCjlUf4"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGHr-V6pFCFw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f34f89b-2e5f-4f3e-c320-1804ef42cd6f"
      },
      "source": [
        "#changes \n",
        "#Added a extra convolution in the encoder part lets look if it makes improvement or not \n",
        "def squeeze_excite_block(inputs, ratio=8):\n",
        "    init = inputs\n",
        "    channel_axis = -1\n",
        "    filters = init.shape[channel_axis]\n",
        "    se_shape = (1, 1, filters)\n",
        "\n",
        "    se = GlobalAveragePooling2D()(init)\n",
        "    se = Reshape(se_shape)(se)\n",
        "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "\n",
        "    x = Multiply()([init, se])\n",
        "    return x\n",
        "def encoder_conv_block(inputs,filters):\n",
        "  x = Conv2D(filters, (3, 3), padding=\"same\",kernel_initializer='he_normal')(inputs)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU(alpha=0.001)(x)\n",
        "  x = Conv2D(filters, (3, 3), padding=\"same\",kernel_initializer='he_normal')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU(alpha=0.001)(x)\n",
        "  return x \n",
        "def decoder_conv_block(inputs,filters,filters2):\n",
        "  x = Conv2D(filters, (3, 3), padding=\"same\",kernel_initializer='he_normal')(inputs)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU(alpha=0.001)(x)\n",
        "  x = Conv2D(filters2, (3, 3), padding=\"same\",kernel_initializer='he_normal')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU(alpha=0.001)(x)\n",
        "  return x\n",
        "\n",
        "def experiment(inputs, ratio=8):\n",
        "    init = inputs\n",
        "    channel_axis = -1\n",
        "    filters = init.shape[channel_axis]\n",
        "    se_shape = (1, 1, filters)\n",
        "\n",
        "    se = GlobalAveragePooling2D()(init)\n",
        "    se = Reshape(se_shape)(se)\n",
        "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "  \n",
        "    return se\n",
        "\n",
        "def encoder(inputs):\n",
        "  num_filters = [32,64,128,256,256]\n",
        "  x= inputs\n",
        "  skip_connections= []\n",
        "  for i,filters  in enumerate(num_filters):\n",
        "    x = encoder_conv_block(x,filters)\n",
        "    print(x.shape)\n",
        "    if i in [1,2,3]:\n",
        "      added_layer = experiment(x)\n",
        "\n",
        "      print(added_layer.shape)\n",
        "      skip_connections.append(added_layer)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "  return x ,skip_connections\n",
        "def decoder(x,skip_layers):\n",
        "  skip_layers.reverse()\n",
        "  num_filters = [32,64, 128,256,256,512]\n",
        "  num_filters.reverse()\n",
        "  for i in range(len(num_filters)-1):\n",
        "    x = decoder_conv_block(x,num_filters[i],num_filters[i+1])\n",
        "    x = UpSampling2D((2,2))(x)\n",
        "    print(x.shape)\n",
        "    if i in [1, 2,3]:\n",
        "      x= Multiply()([x,skip_layers[i-1]])\n",
        "      print(skip_layers[i-1].shape)\n",
        "  return x\n",
        "def output_block(inputs,classes):\n",
        "    x = Conv2D(classes,(1, 1), padding=\"same\")(inputs)\n",
        "    return x\n",
        "def main_model(shape):\n",
        "  inputs = Input(shape)\n",
        "  encoded,skip_layers= encoder(inputs)\n",
        "  decoded = decoder(encoded,skip_layers)\n",
        "  output = output_block(decoded,classes=38)\n",
        "  model = Model(inputs,output)\n",
        "  return model\n",
        "\n",
        "model = main_model((480,640,3))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 480, 640, 32)\n",
            "(None, 240, 320, 64)\n",
            "(None, 1, 1, 64)\n",
            "(None, 120, 160, 128)\n",
            "(None, 1, 1, 128)\n",
            "(None, 60, 80, 256)\n",
            "(None, 1, 1, 256)\n",
            "(None, 30, 40, 256)\n",
            "(None, 30, 40, 256)\n",
            "(None, 60, 80, 256)\n",
            "(None, 1, 1, 256)\n",
            "(None, 120, 160, 128)\n",
            "(None, 1, 1, 128)\n",
            "(None, 240, 320, 64)\n",
            "(None, 1, 1, 64)\n",
            "(None, 480, 640, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5OPWbZNKuPM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce719ee7-02ad-482a-9b75-bdb29e0317fb"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 480, 640, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 480, 640, 32) 896         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 480, 640, 32) 128         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_20 (LeakyReLU)      (None, 480, 640, 32) 0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 480, 640, 32) 9248        leaky_re_lu_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 480, 640, 32) 128         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_21 (LeakyReLU)      (None, 480, 640, 32) 0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 240, 320, 32) 0           leaky_re_lu_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 240, 320, 64) 18496       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 240, 320, 64) 256         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_22 (LeakyReLU)      (None, 240, 320, 64) 0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 240, 320, 64) 36928       leaky_re_lu_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 240, 320, 64) 256         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_23 (LeakyReLU)      (None, 240, 320, 64) 0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 120, 160, 64) 0           leaky_re_lu_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 120, 160, 128 73856       max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 120, 160, 128 512         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_24 (LeakyReLU)      (None, 120, 160, 128 0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 120, 160, 128 147584      leaky_re_lu_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 120, 160, 128 512         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_25 (LeakyReLU)      (None, 120, 160, 128 0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 60, 80, 128)  0           leaky_re_lu_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 60, 80, 256)  295168      max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 60, 80, 256)  1024        conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_26 (LeakyReLU)      (None, 60, 80, 256)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 60, 80, 256)  590080      leaky_re_lu_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 60, 80, 256)  1024        conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_27 (LeakyReLU)      (None, 60, 80, 256)  0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 30, 40, 256)  0           leaky_re_lu_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 30, 40, 256)  590080      max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 30, 40, 256)  1024        conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_28 (LeakyReLU)      (None, 30, 40, 256)  0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 30, 40, 256)  590080      leaky_re_lu_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 30, 40, 256)  1024        conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_29 (LeakyReLU)      (None, 30, 40, 256)  0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2D)  (None, 15, 20, 256)  0           leaky_re_lu_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 15, 20, 512)  1180160     max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 15, 20, 512)  2048        conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_30 (LeakyReLU)      (None, 15, 20, 512)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 15, 20, 256)  1179904     leaky_re_lu_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 15, 20, 256)  1024        conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_31 (LeakyReLU)      (None, 15, 20, 256)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 30, 40, 256)  0           leaky_re_lu_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 30, 40, 256)  590080      up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 30, 40, 256)  1024        conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_32 (LeakyReLU)      (None, 30, 40, 256)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 30, 40, 256)  590080      leaky_re_lu_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_5 (Glo (None, 256)          0           leaky_re_lu_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 30, 40, 256)  1024        conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_5 (Reshape)             (None, 1, 1, 256)    0           global_average_pooling2d_5[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_33 (LeakyReLU)      (None, 30, 40, 256)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 1, 1, 32)     8192        reshape_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2D)  (None, 60, 80, 256)  0           leaky_re_lu_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 1, 1, 256)    8192        dense_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "multiply_3 (Multiply)           (None, 60, 80, 256)  0           up_sampling2d_6[0][0]            \n",
            "                                                                 dense_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 60, 80, 256)  590080      multiply_3[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 60, 80, 256)  1024        conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_34 (LeakyReLU)      (None, 60, 80, 256)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 60, 80, 128)  295040      leaky_re_lu_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_4 (Glo (None, 128)          0           leaky_re_lu_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 60, 80, 128)  512         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_4 (Reshape)             (None, 1, 1, 128)    0           global_average_pooling2d_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_35 (LeakyReLU)      (None, 60, 80, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 1, 1, 16)     2048        reshape_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_7 (UpSampling2D)  (None, 120, 160, 128 0           leaky_re_lu_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 1, 1, 128)    2048        dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "multiply_4 (Multiply)           (None, 120, 160, 128 0           up_sampling2d_7[0][0]            \n",
            "                                                                 dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 120, 160, 128 147584      multiply_4[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 120, 160, 128 512         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_36 (LeakyReLU)      (None, 120, 160, 128 0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 120, 160, 64) 73792       leaky_re_lu_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_3 (Glo (None, 64)           0           leaky_re_lu_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 120, 160, 64) 256         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_3 (Reshape)             (None, 1, 1, 64)     0           global_average_pooling2d_3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_37 (LeakyReLU)      (None, 120, 160, 64) 0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 1, 1, 8)      512         reshape_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_8 (UpSampling2D)  (None, 240, 320, 64) 0           leaky_re_lu_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 1, 1, 64)     512         dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "multiply_5 (Multiply)           (None, 240, 320, 64) 0           up_sampling2d_8[0][0]            \n",
            "                                                                 dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 240, 320, 64) 36928       multiply_5[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 240, 320, 64) 256         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_38 (LeakyReLU)      (None, 240, 320, 64) 0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 240, 320, 32) 18464       leaky_re_lu_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 240, 320, 32) 128         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_39 (LeakyReLU)      (None, 240, 320, 32) 0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_9 (UpSampling2D)  (None, 480, 640, 32) 0           leaky_re_lu_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 480, 640, 38) 1254        up_sampling2d_9[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 7,090,982\n",
            "Trainable params: 7,084,134\n",
            "Non-trainable params: 6,848\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaSnZSXvyIj0"
      },
      "source": [
        "#june 18 5000 with an additional conv layer ..faster but not more accurate i guess"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzHtdx6wNevn"
      },
      "source": [
        "#loss function \n",
        "\n",
        "import gc \n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import CSVLogger ,LearningRateScheduler,Callback\n",
        "class ClearMemory(Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch%1==0:\n",
        "            v_steps=valid_size//16\n",
        "            loss = model.evaluate(valid_dataset,steps=v_steps)\n",
        "            logs['val_loss'] = loss[0]\n",
        "            logs['val_custom_metrics'] = loss[1]\n",
        "            gc.collect()\n",
        "            tf.keras.backend.clear_session()\n",
        "            tf.compat.v1.reset_default_graph() \n",
        "        gc.collect()\n",
        "        tf.keras.backend.clear_session()\n",
        "        tf.compat.v1.reset_default_graph() \n",
        "        return\n",
        "    # def on_train_batch_end(self,batch,logs=None):\n",
        "    #     print('memory usesd: ' + str(psutil.virtual_memory().used // 1e6)) \n",
        "\n",
        "filepath= '/content/drive/MyDrive/experiment-layers/june-19-skip-layers/checkpoint/'\n",
        "directory= filepath\n",
        "# if not os.path.exists(directory):\n",
        "#     os.makedirs(directory)\n",
        "callbacks = [\n",
        "    ClearMemory(),   \n",
        "    EarlyStopping(monitor='val_custom_metrics', patience=3),\n",
        "    ModelCheckpoint(filepath,save_weights_only=True, monitor='val_custom_metrics',verbose=1,mode='max',save_best_only=True),\n",
        "    # LearningRateScheduler(lrfn, verbose = True)\n",
        "    \n",
        "]\n",
        "# loss = tf.keras.losses.categorical_crossentropy(from_logits=True)\n",
        "def binary_loss(y_true, y_pred):\n",
        "    loss = binary_crossentropy(y_true, y_pred,from_logits=True)\n",
        "    loss_value = tf.math.reduce_mean(loss,axis=[0])\n",
        "    return loss_value\n",
        "# loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True, )\n",
        "# def cross_entropy_loss(y_true,y_pred):\n",
        "#     return loss(y_true,y_pred)\n",
        "def cross_entropy_loss(y_true,y_pred):\n",
        "    loss = tf.nn.softmax_cross_entropy_with_logits(\n",
        "    y_true, y_pred, axis=-1, name=None)\n",
        "    return loss\n",
        "\n",
        "def custom_metrics(y_true,y_pred,smooth=1):\n",
        "    y_pred = tf.math.argmax(y_pred, axis=-1)\n",
        "    # y_pred = tf.expand_dims(y_pred,axis=-1)\n",
        "    y_pred = tf.one_hot(y_pred,38)\n",
        "    y_true = y_true[:,:,:,1:38]\n",
        "    y_pred= y_pred[:,:,:,1:38]\n",
        "    intersection  = tf.math.reduce_sum((y_true*y_pred),axis = [1,2,3])\n",
        "    union = (tf.math.reduce_sum(y_true,axis=[1,2,3])+tf.math.reduce_sum(y_pred,axis = [1,2,3])) - intersection\n",
        "    return tf.math.reduce_mean((intersection+smooth)/(union+smooth),axis=0)\n",
        "smooth = 1\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true = tf.keras.layers.Flatten()(y_true)\n",
        "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
        "model.load_weights('/content/drive/MyDrive/experiment-layers/june-19-skip-layers/checkpoint/')\n",
        "# model=tf.keras.models.load_model('/content/drive/MyDrive/training-daily/july19-5000-more-filters/checkpoint/',custom_objects={\n",
        "#         'cross_entropy_loss': cross_entropy_loss ,'dice_coef': dice_coef,'custom_metrics':custom_metrics})\n",
        "model.compile(loss = cross_entropy_loss,optimizer=Adam(learning_rate =.001),metrics=[custom_metrics])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "id6vh8YpLOc0"
      },
      "source": [
        "\n",
        "# epoch=[1,2,3,4]\n",
        "# t_steps=train_size//16\n",
        "# for i in epoch:\n",
        "#   model.fit(train_dataset,epochs=i,initial_epoch=i-1,steps_per_epoch=t_steps,callbacks=callbacks)\n",
        "#   tf.keras.backend.clear_session()\n",
        "#   gc.collect()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOu4GKVVOpis",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a572e1d4-2969-452f-edb7-853f4356b68a"
      },
      "source": [
        "# %%file mprun_demo.py\n",
        "def train(epoch):\n",
        "    t_steps=train_size//16\n",
        "    v_steps=valid_size//16\n",
        "    model.fit(train_dataset, \n",
        "                            epochs =epoch ,\n",
        "                            steps_per_epoch = t_steps,\n",
        "                            callbacks=callbacks)\n",
        "    \n",
        "train(8)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "312/312 [==============================] - 620s 2s/step - loss: 1.7180 - custom_metrics: 0.2830\n",
            "62/62 [==============================] - 79s 1s/step - loss: 1.7994 - custom_metrics: 0.2938\n",
            "\n",
            "Epoch 00001: val_custom_metrics improved from -inf to 0.29379, saving model to /content/drive/MyDrive/experiment-layers/june-19-skip-layers/checkpoint/\n",
            "Epoch 2/8\n",
            "312/312 [==============================] - 553s 2s/step - loss: 1.6733 - custom_metrics: 0.2923\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_custom_metrics` which is not available. Available metrics are: loss,custom_metrics\n",
            "WARNING:tensorflow:Can save best model only with val_custom_metrics available, skipping.\n",
            "Epoch 3/8\n",
            "312/312 [==============================] - 551s 2s/step - loss: 1.6311 - custom_metrics: 0.3044\n",
            "62/62 [==============================] - 80s 1s/step - loss: 1.6743 - custom_metrics: 0.3201\n",
            "\n",
            "Epoch 00003: val_custom_metrics improved from 0.29379 to 0.32006, saving model to /content/drive/MyDrive/experiment-layers/june-19-skip-layers/checkpoint/\n",
            "Epoch 4/8\n",
            "312/312 [==============================] - 546s 2s/step - loss: 1.5900 - custom_metrics: 0.3154\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_custom_metrics` which is not available. Available metrics are: loss,custom_metrics\n",
            "WARNING:tensorflow:Can save best model only with val_custom_metrics available, skipping.\n",
            "Epoch 5/8\n",
            "312/312 [==============================] - 546s 2s/step - loss: 1.5578 - custom_metrics: 0.3247\n",
            "62/62 [==============================] - 85s 1s/step - loss: 1.6554 - custom_metrics: 0.3182\n",
            "\n",
            "Epoch 00005: val_custom_metrics did not improve from 0.32006\n",
            "Epoch 6/8\n",
            "312/312 [==============================] - 549s 2s/step - loss: 1.5218 - custom_metrics: 0.3347\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_custom_metrics` which is not available. Available metrics are: loss,custom_metrics\n",
            "WARNING:tensorflow:Can save best model only with val_custom_metrics available, skipping.\n",
            "Epoch 7/8\n",
            "312/312 [==============================] - 551s 2s/step - loss: 1.4913 - custom_metrics: 0.3442\n",
            " 8/62 [==>...........................] - ETA: 1:42 - loss: 1.6382 - custom_metrics: 0.3051"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8YPykz0GFDX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5n5u2rNt6uR"
      },
      "source": [
        "model = main_model((480,640,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJYCUWEPhhIW"
      },
      "source": [
        "optimizer = Adam(learning_rate=.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5l4dX3mcuqB"
      },
      "source": [
        "@tf.function\n",
        "def train_step(x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model(x, training=True)\n",
        "        loss_value = (cross_entropy_loss(y, logits))\n",
        "    # loss_value =tf.math.reduce_mean(loss_value,axis=[0,1,2])\n",
        "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    train_acc_metrics =  custom_metrics(y, logits)\n",
        "    return loss_value,train_acc_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvyT2NkxcwSN"
      },
      "source": [
        "@tf.function\n",
        "def test_step(x, y):\n",
        "    val_logits = model(x, training=False)\n",
        "    val_acc_metric = (y, val_logits)\n",
        "    val_loss = cross_entropy_loss(u,val_logits)\n",
        "    return val_acc_metric,val_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASeFqZ_DdAwj"
      },
      "source": [
        "# import time\n",
        "# epochs = 4\n",
        "# batch_size = 16\n",
        "# for epoch in range(epochs):\n",
        "#     print(\"\\nStart of epoch %d\", (epoch))\n",
        "#     start_time = time.time()\n",
        "#     for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "#         loss_value,loss_metrics = train_step(x_batch_train, y_batch_train)\n",
        "#         print(step, loss_value,loss_metrics)\n",
        "#         print(\"Seen so far: samples\", (step + 1))\n",
        "#     # print(\"Training acc over epoch: %.4f\" train_acc)\n",
        "#     val_losses = 0\n",
        "#     val_metrics=0\n",
        "#     for val_steps,(x_batch_val, y_batch_val) in enumerate(valid_dataset):\n",
        "#         val_metic,val_loss = test_step(x_batch_val, y_batch_val)\n",
        "#         val_losses +=val_loss\n",
        "#         val_metrics +=val_metric\n",
        "#     print(\"Validation loss: %.4f\",(val_losses/val_steps))\n",
        "#     print('validation custom metrics',val_metrics/val_steps)\n",
        "#     print(\"Time taken: %.2fs\" % (time.time() - start_time))\n",
        "#     gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8GwH6gcPnRZ"
      },
      "source": [
        "def read_image(path):\n",
        "    x = cv.imread(path, cv.IMREAD_COLOR)\n",
        "    x = cv.resize(x,(640,480),interpolation=cv.INTER_AREA)\n",
        "    x = x/255.0\n",
        "    x=tf.cast(x,dtype=tf.float32)\n",
        "    return x\n",
        "\n",
        "def read_mask(path):\n",
        "    x = cv.imread(path, cv.IMREAD_GRAYSCALE)\n",
        "    x = cv.resize(x,(640,480),interpolation=cv.INTER_AREA)\n",
        "    x = to_categorical(x,num_classes=no_classes+1)\n",
        "    x = x[:,:,:]\n",
        "    # x = np.expand_dims(x, axis=-1)\n",
        "    # x=np.concatenate([x,x],axis=-1)\n",
        "    x=tf.cast(x,dtype=tf.float32)\n",
        "    return x\n",
        "def custom_metrics(y_true,y_pred,smooth=1):\n",
        "    y_pred = tf.math.argmax(y_pred, axis=-1)\n",
        "    # y_pred = tf.expand_dims(y_pred,axis=-1)\n",
        "    y_pred = tf.one_hot(y_pred,38)\n",
        "    y_true = y_true[:,:,:,1:38]\n",
        "    y_pred= y_pred[:,:,:,1:38]\n",
        "    intersection  = tf.math.reduce_sum((y_true*y_pred),axis = [1,2,3])\n",
        "    union = tf.math.reduce_sum(y_true,axis=[1,2,3])+tf.math.reduce_sum(y_pred,axis = [1,2,3]) - intersection \n",
        "    return tf.math.reduce_mean((intersection+smooth)/(union+smooth),axis=0)\n",
        "def load_data(images,masks):\n",
        "    length = 1990\n",
        "    iou=0\n",
        "    for i,(image,mask) in enumerate(zip(images,masks)):\n",
        "    \n",
        "      img = read_image(image)\n",
        "      mas = read_mask(mask)\n",
        "      img = np.expand_dims(img,0)\n",
        "      mas = np.expand_dims(mas,0)\n",
        "      prediction = model.predict(img)\n",
        "      iou += custom_metrics(mas,prediction)\n",
        "      print(i,iou)\n",
        "    return iou/length\n",
        "no_classes=37\n",
        "print(len(test_x))\n",
        "x=load_data(test_x,test_y)\n",
        "print('*****************************************************************************************************************')\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXH9XLBMM2bB"
      },
      "source": [
        "model2 = main_model2(shape,no_classes)\n",
        "model2=tf.keras.models.load_model(filepath2,custom_objects={'cross_entropy_loss':cross_entropy_loss,'dice_coef':dice_coef,'custom_metrics':custom_metrics})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-gQ6TBDMf4B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZsGANPHM1T5"
      },
      "source": [
        "import matplotlib\n",
        "cmap = matplotlib.colors.ListedColormap(color_list)\n",
        "def plot(image,numpy,prediction):\n",
        "    plt.figure(figsize=(14,14))\n",
        "    plt.subplot(131)\n",
        "    plt.imshow(np.squeeze(prediction)+1,cmap=cmap,vmin=1, vmax=len(color_list))\n",
        "    plt.subplot(132)\n",
        "    plt.imshow(image)\n",
        "    plt.subplot(133)\n",
        "    plt.imshow(numpy,cmap='gray')\n",
        "    print(prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irZ0RNFNVg5q"
      },
      "source": [
        "import matplotlib\n",
        "def plot(image,numpy,prediction):\n",
        "    plt.figure(figsize=(14,14))\n",
        "    plt.subplot(131)\n",
        "    plt.imshow(np.squeeze(prediction),cmap=plt.get_cmap('gray'))\n",
        "    plt.subplot(132)\n",
        "    plt.imshow(image)\n",
        "    plt.subplot(133)\n",
        "    plt.imshow(numpy,cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiDguJ9C-6Pg"
      },
      "source": [
        "def prediction(path):\n",
        "    image = cv.imread(path,cv.IMREAD_COLOR)\n",
        "    x = cv.resize(image,(640,480),interpolation=cv.INTER_NEAREST)\n",
        "    x = x/255.0\n",
        "    x=np.expand_dims(x,0)\n",
        "    y = model.predict(x)\n",
        "    print(y.shape)\n",
        "    numpy = np.zeros((y.shape[1],y.shape[2],y.shape[3]))\n",
        "    print(numpy.shape)\n",
        "    numpy[:,:,:] = y \n",
        "    prediction= numpy.argmax(axis=-1)\n",
        "    print(prediction.shape)\n",
        "    numpy= tf.one_hot(prediction,38)\n",
        "    plot(image,numpy[:,:,2],prediction)\n",
        "    return numpy\n",
        "path = '/content/drive/MyDrive/depth/image/image1.jpg'\n",
        "prediction1=prediction(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb2AVBOiBwYB"
      },
      "source": [
        "for i in range(prediction1.shape[2]):\n",
        "    # for j in range(prediction1.shape[1]):\n",
        "    #     # if prediction1[i,j]>2:\n",
        "    (prediction1.shape)\n",
        "    print(prediction1[])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZIgQWQFHcr7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}