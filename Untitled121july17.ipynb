{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled121july17.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sameepshrestha/segmentation_state_of_the_art/blob/main/Untitled121july17.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kTMpcSd1YrH"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPSbYPZyCIvP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bc07a74-407c-4645-a6cb-7c7c9e94db96"
      },
      "source": [
        "# model.summary()\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXMEt7jkCaVW"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "import numpy as np \n",
        "import cv2 as cv \n",
        "from PIL import Image, ImageDraw\n",
        "import json \n",
        "import os \n",
        "import glob \n",
        "import re \n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf \n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Reshape, Concatenate,MaxPooling2D, AveragePooling2D,Input, BatchNormalization, Activation, UpSampling2D, Concatenate, LeakyReLU,Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam \n",
        "#using tensorflow backend 16 so keras backend still 32bytes so no keras to be used\n",
        "# from keras.layers.merge import concatenate,Concatenate\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gc\n",
        "import psutil"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_maY0bRpS38"
      },
      "source": [
        "import math\n",
        "import sys, time\n",
        "\n",
        "# Interpolation kernel\n",
        "def u(s,a):\n",
        "    if (abs(s) >=0) & (abs(s) <=1):\n",
        "        return (a+2)*(abs(s)**3)-(a+3)*(abs(s)**2)+1\n",
        "    elif (abs(s) > 1) & (abs(s) <= 2):\n",
        "        return a*(abs(s)**3)-(5*a)*(abs(s)**2)+(8*a)*abs(s)-4*a\n",
        "    return 0\n",
        "\n",
        "#Paddnig\n",
        "def padding(img,H,W,C):\n",
        "    zimg = np.zeros((H+4,W+4,C))\n",
        "    zimg[2:H+2,2:W+2,:C] = img\n",
        "    zimg[2:H+2,0:2,:C]=img[:,0:1,:C]\n",
        "    zimg[H+2:H+4,2:W+2,:]=img[H-1:H,:,:]\n",
        "    zimg[2:H+2,W+2:W+4,:]=img[:,W-1:W,:]\n",
        "    zimg[0:2,2:W+2,:C]=img[0:1,:,:C]\n",
        "    zimg[0:2,0:2,:C]=img[0,0,:C]\n",
        "    zimg[H+2:H+4,0:2,:C]=img[H-1,0,:C]\n",
        "    zimg[H+2:H+4,W+2:W+4,:C]=img[H-1,W-1,:C]\n",
        "    zimg[0:2,W+2:W+4,:C]=img[0,W-1,:C]\n",
        "    return zimg\n",
        "\n",
        "# https://github.com/rootpine\n",
        "# Bicubic operation\n",
        "def UPsampling_cubic(img, ratio, a):\n",
        "    #Get image size\n",
        "    H,W,C = img.shape\n",
        "\n",
        "    img = padding(img,H,W,C)\n",
        "    #Create new image\n",
        "    dH = math.floor(H*ratio)\n",
        "    dW = math.floor(W*ratio)\n",
        "    dst = np.zeros((dH, dW, 3))\n",
        "\n",
        "    h = 1/ratio\n",
        "\n",
        "    print('Start bicubic interpolation')\n",
        "    print('It will take a little while...')\n",
        "    inc = 0\n",
        "    for c in range(C):\n",
        "        for j in range(dH):\n",
        "            for i in range(dW):\n",
        "                x, y = i * h + 2 , j * h + 2\n",
        "\n",
        "                x1 = 1 + x - math.floor(x)\n",
        "                x2 = x - math.floor(x)\n",
        "                x3 = math.floor(x) + 1 - x\n",
        "                x4 = math.floor(x) + 2 - x\n",
        "\n",
        "                y1 = 1 + y - math.floor(y)\n",
        "                y2 = y - math.floor(y)\n",
        "                y3 = math.floor(y) + 1 - y\n",
        "                y4 = math.floor(y) + 2 - y\n",
        "\n",
        "                mat_l = np.matrix([[u(x1,a),u(x2,a),u(x3,a),u(x4,a)]])\n",
        "                mat_m = np.matrix([[img[int(y-y1),int(x-x1),c],img[int(y-y2),int(x-x1),c],img[int(y+y3),int(x-x1),c],img[int(y+y4),int(x-x1),c]],\n",
        "                                   [img[int(y-y1),int(x-x2),c],img[int(y-y2),int(x-x2),c],img[int(y+y3),int(x-x2),c],img[int(y+y4),int(x-x2),c]],\n",
        "                                   [img[int(y-y1),int(x+x3),c],img[int(y-y2),int(x+x3),c],img[int(y+y3),int(x+x3),c],img[int(y+y4),int(x+x3),c]],\n",
        "                                   [img[int(y-y1),int(x+x4),c],img[int(y-y2),int(x+x4),c],img[int(y+y3),int(x+x4),c],img[int(y+y4),int(x+x4),c]]])\n",
        "                mat_r = np.matrix([[u(y1,a)],[u(y2,a)],[u(y3,a)],[u(y4,a)]])\n",
        "                dst[j, i, c] = np.dot(np.dot(mat_l, mat_m),mat_r)\n",
        "    return dst\n",
        "\n",
        "# Read image\n",
        "img = cv.imread('butterfly.png')\n",
        "\n",
        "# Scale factor\n",
        "ratio = 2\n",
        "# Coefficient\n",
        "a = -1/2\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jYMHKtEL-oK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "040b4e3f-09fb-4cd7-8384-7326f8e5536f"
      },
      "source": [
        "tf.keras.mixed_precision.experimental.set_policy('mixed_float16')\n",
        "# # tf.compat.v1.disable_eager_execution()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
            "Your GPU may run slowly with dtype policy mixed_float16 because it does not have compute capability of at least 7.0. Your GPU:\n",
            "  Tesla K80, compute capability 3.7\n",
            "See https://developer.nvidia.com/cuda-gpus for a list of GPUs and their compute capabilities.\n",
            "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Jl9K0TuK0kZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59dfc70f-5fe9-46bf-f640-46ba427e4ae6"
      },
      "source": [
        "category = \"\"\"wall, floor, cabinet, bed, chair, sofa, table, door, window, bookshelf, picture, counter, blinds, desk, shelves, curtain, dresser\n",
        ", pillow, mirror, floor mat, clothes, ceiling, books, fridge, tv, paper, towel, shower curtain, box, whiteboard, person, nightstand, toilet, sink\n",
        ", lamp, bathtub, bag\"\"\"\n",
        "category = category.split(r', ')\n",
        "category = [i.replace('\\n','') for i in category]\n",
        "category_1 = ['background']\n",
        "for categ in category:category_1.append(categ) \n",
        "print(category_1)\n",
        "category_dict = {k:category_1.index(k) for k in category_1}\n",
        "print(category_dict)\n",
        "reverse_map={i:k for k,i in category_dict.items()}\n",
        "color_list=['gray','red','green','#FFFF00','#8c564b','#4B8BBE','#306998','#FFE873','#FFD43B','#646464','#5a0000','#003a27','#C0C0C0','#808080','#800000','#808000','#00FF00','#00FFFF','#008080','#000080','#FF00FF','#800080','#CD5C5C','#F08080','#FA8072','#E9967A','#FFA07A','#DC143C','#FF7F50','#FFD700','#ffffe0','#bdb76b','#228b22','#B0E0E6','#4169e1','#f0ffff','#d2691e','#BC8F8F']\n",
        "class_color_map={k:color_list[i] for i,k in enumerate(reverse_map.keys())}"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['background', 'wall', 'floor', 'cabinet', 'bed', 'chair', 'sofa', 'table', 'door', 'window', 'bookshelf', 'picture', 'counter', 'blinds', 'desk', 'shelves', 'curtain', 'dresser', 'pillow', 'mirror', 'floor mat', 'clothes', 'ceiling', 'books', 'fridge', 'tv', 'paper', 'towel', 'shower curtain', 'box', 'whiteboard', 'person', 'nightstand', 'toilet', 'sink', 'lamp', 'bathtub', 'bag']\n",
            "{'background': 0, 'wall': 1, 'floor': 2, 'cabinet': 3, 'bed': 4, 'chair': 5, 'sofa': 6, 'table': 7, 'door': 8, 'window': 9, 'bookshelf': 10, 'picture': 11, 'counter': 12, 'blinds': 13, 'desk': 14, 'shelves': 15, 'curtain': 16, 'dresser': 17, 'pillow': 18, 'mirror': 19, 'floor mat': 20, 'clothes': 21, 'ceiling': 22, 'books': 23, 'fridge': 24, 'tv': 25, 'paper': 26, 'towel': 27, 'shower curtain': 28, 'box': 29, 'whiteboard': 30, 'person': 31, 'nightstand': 32, 'toilet': 33, 'sink': 34, 'lamp': 35, 'bathtub': 36, 'bag': 37}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH44_RJvK9TL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e7ce761-c2a4-4e1a-d308-2df0de5364c9"
      },
      "source": [
        "\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "Image_width = 640 \n",
        "Image_height = 480 \n",
        "no_classes = len(category_dict)\n",
        "def load_data(path, split=0.2):\n",
        "    images = sorted(glob.glob(os.path.join(path, \"image/*\")))\n",
        "    print(len(images))\n",
        "    masks = sorted(glob.glob(os.path.join(path, \"mask/*\")))\n",
        "    print(len(masks))\n",
        "    total_size = 7990\n",
        "    test_size = 1990\n",
        "    valid_size=1000\n",
        "    training_x, test_x = train_test_split(images[:7990], test_size=test_size, random_state=42)\n",
        "    training_y, test_y = train_test_split(masks[:7990], test_size=test_size, random_state=42)\n",
        "    train_x, valid_x = train_test_split(training_x, test_size=valid_size, random_state=42)\n",
        "    train_y, valid_y = train_test_split(training_y, test_size=valid_size, random_state=42)\n",
        "    return (train_x, train_y), (valid_x, valid_y),(test_x, test_y)\n",
        "(train_x,train_y),(valid_x,valid_y),(test_x, test_y)=load_data('/content/drive/MyDrive/depth')\n",
        "train_size=len(train_x)\n",
        "valid_size=len(valid_x)\n",
        "\n",
        "def read_image(path):\n",
        "    path = path.decode()\n",
        "    x = cv.imread(path, cv.IMREAD_COLOR)\n",
        "    x = cv.resize(x,(640,480),interpolation=cv.INTER_AREA)\n",
        "    x = x/255.0\n",
        "    x=tf.cast(x,dtype=tf.float32)\n",
        "    return x\n",
        "\n",
        "def read_mask(path):\n",
        "    path = path.decode()\n",
        "    x = cv.imread(path, cv.IMREAD_GRAYSCALE)\n",
        "    x = cv.resize(x,(640,480),interpolation=cv.INTER_NEAREST)\n",
        "  \n",
        "    x = to_categorical(x,num_classes=no_classes)\n",
        "    x = x[:,:,:]\n",
        "    # x = np.expand_dims(x, axis=-1)\n",
        "    # x=np.concatenate([x,x],axis=-1)\n",
        "    x=tf.cast(x,dtype=tf.float32)\n",
        "    return x\n",
        "# read_mask('/content/drive/MyDrive/depth/mask100/mask1.png')\n",
        "def parser(x,y):\n",
        "    def _parse(x,y):\n",
        "        x=read_image(x)\n",
        "        y=read_mask(y)\n",
        "        return x,y\n",
        "    x,y = tf.numpy_function(_parse, [x,y], [tf.float32,tf.float32])\n",
        "    x.set_shape([Image_height, Image_width, 3])\n",
        "    y.set_shape([Image_height, Image_width, no_classes])\n",
        "    return x,y\n",
        "    \n",
        "def tf_dataset(x, y, batch):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "    dataset = dataset.map(parser)\n",
        "    # dataset = dataset.cache()\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.batch(batch)\n",
        "    dataset = dataset.prefetch(AUTO)\n",
        "    return dataset\n",
        "train_dataset=tf_dataset(train_x,train_y,batch=16)\n",
        "valid_dataset=tf_dataset(valid_x,valid_y,batch=16)\n",
        "valid_dataset"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8033\n",
            "7990\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None, 480, 640, 3), (None, 480, 640, 38)), types: (tf.float32, tf.float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlufJvHAlU4M",
        "outputId": "aceb160c-6cab-47ae-ae1d-156c34def004"
      },
      "source": [
        "print(test_x[:100])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/drive/MyDrive/depth/image/image5457.jpg', '/content/drive/MyDrive/depth/image/image5917.jpg', '/content/drive/MyDrive/depth/image/image7738.jpg', '/content/drive/MyDrive/depth/image/image7847.jpg', '/content/drive/MyDrive/depth/image/image3387.jpg', '/content/drive/MyDrive/depth/image/image516.jpg', '/content/drive/MyDrive/depth/image/image1978.jpg', '/content/drive/MyDrive/depth/image/image4452.jpg', '/content/drive/MyDrive/depth/image/image470.jpg', '/content/drive/MyDrive/depth/image/image2603.jpg', '/content/drive/MyDrive/depth/image/image3895.jpg', '/content/drive/MyDrive/depth/image/image5776.jpg', '/content/drive/MyDrive/depth/image/image164.jpg', '/content/drive/MyDrive/depth/image/image7588.jpg', '/content/drive/MyDrive/depth/image/image5720.jpg', '/content/drive/MyDrive/depth/image/image2827.jpg', '/content/drive/MyDrive/depth/image/image1903.jpg', '/content/drive/MyDrive/depth/image/image5203.jpg', '/content/drive/MyDrive/depth/image/image2773.jpg', '/content/drive/MyDrive/depth/image/image1729.jpg', '/content/drive/MyDrive/depth/image/image2831.jpg', '/content/drive/MyDrive/depth/image/image4291.jpg', '/content/drive/MyDrive/depth/image/image1213.jpg', '/content/drive/MyDrive/depth/image/image7546.jpg', '/content/drive/MyDrive/depth/image/image249.jpg', '/content/drive/MyDrive/depth/image/image429.jpg', '/content/drive/MyDrive/depth/image/image2278.jpg', '/content/drive/MyDrive/depth/image/image7784.jpg', '/content/drive/MyDrive/depth/image/image5716.jpg', '/content/drive/MyDrive/depth/image/image3109.jpg', '/content/drive/MyDrive/depth/image/image4577.jpg', '/content/drive/MyDrive/depth/image/image2260.jpg', '/content/drive/MyDrive/depth/image/image1661.jpg', '/content/drive/MyDrive/depth/image/image2164.jpg', '/content/drive/MyDrive/depth/image/image48.jpg', '/content/drive/MyDrive/depth/image/image2817.jpg', '/content/drive/MyDrive/depth/image/image2400.jpg', '/content/drive/MyDrive/depth/image/image1285.jpg', '/content/drive/MyDrive/depth/image/image1954.jpg', '/content/drive/MyDrive/depth/image/image3078.jpg', '/content/drive/MyDrive/depth/image/image1923.jpg', '/content/drive/MyDrive/depth/image/image141.jpg', '/content/drive/MyDrive/depth/image/image1235.jpg', '/content/drive/MyDrive/depth/image/image7963.jpg', '/content/drive/MyDrive/depth/image/image3071.jpg', '/content/drive/MyDrive/depth/image/image7259.jpg', '/content/drive/MyDrive/depth/image/image3418.jpg', '/content/drive/MyDrive/depth/image/image1199.jpg', '/content/drive/MyDrive/depth/image/image7328.jpg', '/content/drive/MyDrive/depth/image/image4750.jpg', '/content/drive/MyDrive/depth/image/image1286.jpg', '/content/drive/MyDrive/depth/image/image7629.jpg', '/content/drive/MyDrive/depth/image/image4930.jpg', '/content/drive/MyDrive/depth/image/image1907.jpg', '/content/drive/MyDrive/depth/image/image2053.jpg', '/content/drive/MyDrive/depth/image/image1465.jpg', '/content/drive/MyDrive/depth/image/image4490.jpg', '/content/drive/MyDrive/depth/image/image4884.jpg', '/content/drive/MyDrive/depth/image/image7101.jpg', '/content/drive/MyDrive/depth/image/image949.jpg', '/content/drive/MyDrive/depth/image/image889.jpg', '/content/drive/MyDrive/depth/image/image7615.jpg', '/content/drive/MyDrive/depth/image/image6905.jpg', '/content/drive/MyDrive/depth/image/image4475.jpg', '/content/drive/MyDrive/depth/image/image7420.jpg', '/content/drive/MyDrive/depth/image/image2072.jpg', '/content/drive/MyDrive/depth/image/image2401.jpg', '/content/drive/MyDrive/depth/image/image4131.jpg', '/content/drive/MyDrive/depth/image/image5407.jpg', '/content/drive/MyDrive/depth/image/image3231.jpg', '/content/drive/MyDrive/depth/image/image4194.jpg', '/content/drive/MyDrive/depth/image/image2947.jpg', '/content/drive/MyDrive/depth/image/image4459.jpg', '/content/drive/MyDrive/depth/image/image2558.jpg', '/content/drive/MyDrive/depth/image/image4706.jpg', '/content/drive/MyDrive/depth/image/image7327.jpg', '/content/drive/MyDrive/depth/image/image1921.jpg', '/content/drive/MyDrive/depth/image/image5978.jpg', '/content/drive/MyDrive/depth/image/image2330.jpg', '/content/drive/MyDrive/depth/image/image7428.jpg', '/content/drive/MyDrive/depth/image/image4878.jpg', '/content/drive/MyDrive/depth/image/image5983.jpg', '/content/drive/MyDrive/depth/image/image3002.jpg', '/content/drive/MyDrive/depth/image/image2780.jpg', '/content/drive/MyDrive/depth/image/image7681.jpg', '/content/drive/MyDrive/depth/image/image7383.jpg', '/content/drive/MyDrive/depth/image/image2913.jpg', '/content/drive/MyDrive/depth/image/image3217.jpg', '/content/drive/MyDrive/depth/image/image7280.jpg', '/content/drive/MyDrive/depth/image/image1312.jpg', '/content/drive/MyDrive/depth/image/image6673.jpg', '/content/drive/MyDrive/depth/image/image452.jpg', '/content/drive/MyDrive/depth/image/image3972.jpg', '/content/drive/MyDrive/depth/image/image3340.jpg', '/content/drive/MyDrive/depth/image/image5157.jpg', '/content/drive/MyDrive/depth/image/image3790.jpg', '/content/drive/MyDrive/depth/image/image6024.jpg', '/content/drive/MyDrive/depth/image/image3771.jpg', '/content/drive/MyDrive/depth/image/image5392.jpg', '/content/drive/MyDrive/depth/image/image7628.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOTZSsCjlUf4"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGHr-V6pFCFw",
        "outputId": "da6a798c-2539-4d36-fcb0-135ec3447568"
      },
      "source": [
        "\n",
        "def conv_block(inputs,filters):\n",
        "  x = Conv2D(filters, (3, 3), padding=\"same\",kernel_initializer='he_normal')(inputs)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU(alpha=0.001)(x)\n",
        "  x = Conv2D(filters, (3, 3), padding=\"same\",kernel_initializer='he_normal')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU(alpha=0.001)(x)\n",
        "  return x \n",
        "\n",
        "def encoder(inputs):\n",
        "  num_filters = [32,64, 128,256,256]\n",
        "  x= inputs\n",
        "  for i,filters  in enumerate(num_filters):\n",
        "    x = conv_block(x,filters)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "  return x \n",
        "def decoder(x):\n",
        "  num_filters = [32,64, 128,256,256]\n",
        "  num_filters.reverse()\n",
        "  for i,filters in enumerate(num_filters):\n",
        "    print(filters)\n",
        "    x = conv_block(x,filters)\n",
        "    x = UpSampling2D((2,2))(x)\n",
        "    \n",
        "  return x\n",
        "def output_block(inputs,classes):\n",
        "    x = Conv2D(classes,(1, 1), padding=\"same\")(inputs)\n",
        "    return x\n",
        "def main_model(shape):\n",
        "  inputs = Input(shape)\n",
        "  encoded = encoder(inputs)\n",
        "  decoded = decoder(encoded)\n",
        "  output = output_block(decoded,classes=38)\n",
        "  model = Model(inputs,output)\n",
        "  return model\n",
        "\n",
        "model = main_model((480,640,3))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "256\n",
            "256\n",
            "128\n",
            "64\n",
            "32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5OPWbZNKuPM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b47f1736-df66-411e-fb87-10c20ad7e44c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 480, 640, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 480, 640, 32)      896       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 480, 640, 32)      128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 480, 640, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 480, 640, 32)      9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 480, 640, 32)      128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 480, 640, 32)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 240, 320, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 240, 320, 64)      18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 240, 320, 64)      256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 240, 320, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 240, 320, 64)      36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 240, 320, 64)      256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 240, 320, 64)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 120, 160, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 120, 160, 128)     73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 120, 160, 128)     512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 120, 160, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 120, 160, 128)     147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 120, 160, 128)     512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 120, 160, 128)     0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 60, 80, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 60, 80, 256)       295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 60, 80, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 60, 80, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 60, 80, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 60, 80, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 60, 80, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 30, 40, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 30, 40, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 30, 40, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 30, 40, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 30, 40, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 30, 40, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 30, 40, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 15, 20, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 15, 20, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 15, 20, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)   (None, 15, 20, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 15, 20, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 15, 20, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)   (None, 15, 20, 256)       0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d (UpSampling2D) (None, 30, 40, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 30, 40, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 30, 40, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)   (None, 30, 40, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 30, 40, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 30, 40, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)   (None, 30, 40, 256)       0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 60, 80, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 60, 80, 128)       295040    \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 60, 80, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)   (None, 60, 80, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 60, 80, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 60, 80, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)   (None, 60, 80, 128)       0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2 (None, 120, 160, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 120, 160, 64)      73792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 120, 160, 64)      256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)   (None, 120, 160, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 120, 160, 64)      36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 120, 160, 64)      256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)   (None, 120, 160, 64)      0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2 (None, 240, 320, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 240, 320, 32)      18464     \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 240, 320, 32)      128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)   (None, 240, 320, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 240, 320, 32)      9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 240, 320, 32)      128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_19 (LeakyReLU)   (None, 240, 320, 32)      0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2 (None, 480, 640, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 480, 640, 38)      1254      \n",
            "=================================================================\n",
            "Total params: 5,306,822\n",
            "Trainable params: 5,300,934\n",
            "Non-trainable params: 5,888\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzHtdx6wNevn"
      },
      "source": [
        "#loss function \n",
        "\n",
        "import gc \n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import CSVLogger ,LearningRateScheduler,Callback\n",
        "class ClearMemory(Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch%4==0:\n",
        "            v_steps=valid_size//16\n",
        "            loss = model.evaluate(valid_dataset,steps=v_steps)\n",
        "            logs['val_loss'] = loss[0]\n",
        "            logs['val_custom_metrics'] = loss[1]\n",
        "        gc.collect()\n",
        "        tf.keras.backend.clear_session()\n",
        "        tf.compat.v1.reset_default_graph() \n",
        "        return\n",
        "    # def on_train_batch_end(self,batch,logs=None):\n",
        "    #     print('memory usesd: ' + str(psutil.virtual_memory().used // 1e6)) \n",
        "\n",
        "\n",
        "filepath= '/content/drive/MyDrive/training-daily/june15-5000/checkpoint/'\n",
        "filepath2 = '/content/drive/MyDrive/training-daily/june15-5000/tensorboard'\n",
        "callbacks = [\n",
        "    ClearMemory(),   \n",
        "    EarlyStopping(monitor='val_custom_metrics', patience=5),\n",
        "    ModelCheckpoint(filepath, monitor='val_custom_metrics',verbose=1,mode='max',save_best_only=True),\n",
        "    # LearningRateScheduler(lrfn, verbose = True)\n",
        "    \n",
        "]\n",
        "# loss = tf.keras.losses.categorical_crossentropy(from_logits=True)\n",
        "def binary_loss(y_true, y_pred):\n",
        "    loss = binary_crossentropy(y_true, y_pred,from_logits=True)\n",
        "    loss_value = tf.math.reduce_mean(loss,axis=[0])\n",
        "    return loss_value\n",
        "# loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True, )\n",
        "# def cross_entropy_loss(y_true,y_pred):\n",
        "#     return loss(y_true,y_pred)\n",
        "def cross_entropy_loss(y_true,y_pred):\n",
        "    loss = tf.nn.softmax_cross_entropy_with_logits(\n",
        "    y_true, y_pred, axis=-1, name=None)\n",
        "    return loss\n",
        "\n",
        "def custom_metrics(y_true,y_pred,smooth=1):\n",
        "    y_pred = tf.math.argmax(y_pred, axis=-1)\n",
        "    # y_pred = tf.expand_dims(y_pred,axis=-1)\n",
        "    y_pred = tf.one_hot(y_pred,38)\n",
        "    y_true = y_true[:,:,:,1:38]\n",
        "    y_pred= y_pred[:,:,:,1:38]\n",
        "    intersection  = tf.math.reduce_sum((y_true*y_pred),axis = [1,2,3])\n",
        "    union = (tf.math.reduce_sum(y_true,axis=[1,2,3])+tf.math.reduce_sum(y_pred,axis = [1,2,3])) - intersection\n",
        "    return tf.math.reduce_mean((intersection+smooth)/(union+smooth),axis=0)\n",
        "smooth = 1\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true = tf.keras.layers.Flatten()(y_true)\n",
        "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
        "model=tf.keras.models.load_model('/content/drive/MyDrive/training-daily/june15-5000/checkpoint/',custom_objects={\n",
        "        'cross_entropy_loss': cross_entropy_loss ,'dice_coef': dice_coef,'custom_metrics':custom_metrics})\n",
        "model.compile(loss = cross_entropy_loss,optimizer=Adam(learning_rate =.001),metrics=[custom_metrics])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "id6vh8YpLOc0"
      },
      "source": [
        "# epoch=[1,2,3,4]\n",
        "# t_steps=train_size//16\n",
        "# for i in epoch:\n",
        "#   model.fit(train_dataset,epochs=i,initial_epoch=i-1,steps_per_epoch=t_steps,callbacks=callbacks)\n",
        "#   tf.keras.backend.clear_session()\n",
        "#   gc.collect()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOu4GKVVOpis",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af5cd013-c086-4591-db2b-bd0746de6b42"
      },
      "source": [
        "# %%file mprun_demo.py\n",
        "def train(epoch):\n",
        "    t_steps=train_size//16\n",
        "    v_steps=valid_size//16\n",
        "    model.fit(train_dataset, \n",
        "                            epochs =epoch ,\n",
        "                            steps_per_epoch = t_steps,\n",
        "                            callbacks=callbacks)\n",
        "    \n",
        "train(17)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/17\n",
            "312/312 [==============================] - 1030s 3s/step - loss: 1.9389 - custom_metrics: 0.2322\n",
            "62/62 [==============================] - 916s 15s/step - loss: 2.0635 - custom_metrics: 0.2135\n",
            "\n",
            "Epoch 00001: val_custom_metrics improved from -inf to 0.21348, saving model to /content/drive/MyDrive/training-daily/june15-5000/checkpoint/\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/training-daily/june15-5000/checkpoint/assets\n",
            "Epoch 2/17\n",
            "312/312 [==============================] - 999s 3s/step - loss: 1.8335 - custom_metrics: 0.2583\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_custom_metrics` which is not available. Available metrics are: loss,custom_metrics\n",
            "WARNING:tensorflow:Can save best model only with val_custom_metrics available, skipping.\n",
            "Epoch 3/17\n",
            "312/312 [==============================] - 996s 3s/step - loss: 1.7759 - custom_metrics: 0.2735\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_custom_metrics` which is not available. Available metrics are: loss,custom_metrics\n",
            "WARNING:tensorflow:Can save best model only with val_custom_metrics available, skipping.\n",
            "Epoch 4/17\n",
            "312/312 [==============================] - 995s 3s/step - loss: 1.7292 - custom_metrics: 0.2837\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_custom_metrics` which is not available. Available metrics are: loss,custom_metrics\n",
            "WARNING:tensorflow:Can save best model only with val_custom_metrics available, skipping.\n",
            "Epoch 5/17\n",
            "312/312 [==============================] - 997s 3s/step - loss: 1.6831 - custom_metrics: 0.2974\n",
            "62/62 [==============================] - 131s 2s/step - loss: 1.7123 - custom_metrics: 0.3052\n",
            "\n",
            "Epoch 00005: val_custom_metrics improved from 0.21348 to 0.30519, saving model to /content/drive/MyDrive/training-daily/june15-5000/checkpoint/\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/training-daily/june15-5000/checkpoint/assets\n",
            "Epoch 6/17\n",
            "312/312 [==============================] - 986s 3s/step - loss: 1.6420 - custom_metrics: 0.3087\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_custom_metrics` which is not available. Available metrics are: loss,custom_metrics\n",
            "WARNING:tensorflow:Can save best model only with val_custom_metrics available, skipping.\n",
            "Epoch 7/17\n",
            "312/312 [==============================] - 991s 3s/step - loss: 1.6075 - custom_metrics: 0.3199\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_custom_metrics` which is not available. Available metrics are: loss,custom_metrics\n",
            "WARNING:tensorflow:Can save best model only with val_custom_metrics available, skipping.\n",
            "Epoch 8/17\n",
            "312/312 [==============================] - 992s 3s/step - loss: 1.5728 - custom_metrics: 0.3290\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_custom_metrics` which is not available. Available metrics are: loss,custom_metrics\n",
            "WARNING:tensorflow:Can save best model only with val_custom_metrics available, skipping.\n",
            "Epoch 9/17\n",
            "312/312 [==============================] - 991s 3s/step - loss: 1.5453 - custom_metrics: 0.3369\n",
            "62/62 [==============================] - 134s 2s/step - loss: 1.6011 - custom_metrics: 0.3312\n",
            "\n",
            "Epoch 00009: val_custom_metrics improved from 0.30519 to 0.33116, saving model to /content/drive/MyDrive/training-daily/june15-5000/checkpoint/\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/training-daily/june15-5000/checkpoint/assets\n",
            "Epoch 10/17\n",
            "312/312 [==============================] - 996s 3s/step - loss: 1.5115 - custom_metrics: 0.3459\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_custom_metrics` which is not available. Available metrics are: loss,custom_metrics\n",
            "WARNING:tensorflow:Can save best model only with val_custom_metrics available, skipping.\n",
            "Epoch 11/17\n",
            "312/312 [==============================] - 997s 3s/step - loss: 1.4853 - custom_metrics: 0.3530\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_custom_metrics` which is not available. Available metrics are: loss,custom_metrics\n",
            "WARNING:tensorflow:Can save best model only with val_custom_metrics available, skipping.\n",
            "Epoch 12/17\n",
            " 86/312 [=======>......................] - ETA: 12:00 - loss: 1.4749 - custom_metrics: 0.3509"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5n5u2rNt6uR"
      },
      "source": [
        "model = main_model((480,640,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJYCUWEPhhIW"
      },
      "source": [
        "optimizer = Adam(learning_rate=.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5l4dX3mcuqB"
      },
      "source": [
        "@tf.function\n",
        "def train_step(x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model(x, training=True)\n",
        "        loss_value = (cross_entropy_loss(y, logits))\n",
        "    # loss_value =tf.math.reduce_mean(loss_value,axis=[0,1,2])\n",
        "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    train_acc_metrics =  custom_metrics(y, logits)\n",
        "    return loss_value,train_acc_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvyT2NkxcwSN"
      },
      "source": [
        "@tf.function\n",
        "def test_step(x, y):\n",
        "    val_logits = model(x, training=False)\n",
        "    val_acc_metric = (y, val_logits)\n",
        "    val_loss = cross_entropy_loss(u,val_logits)\n",
        "    return val_acc_metric,val_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASeFqZ_DdAwj"
      },
      "source": [
        "# import time\n",
        "# epochs = 4\n",
        "# batch_size = 16\n",
        "# for epoch in range(epochs):\n",
        "#     print(\"\\nStart of epoch %d\", (epoch))\n",
        "#     start_time = time.time()\n",
        "#     for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "#         loss_value,loss_metrics = train_step(x_batch_train, y_batch_train)\n",
        "#         print(step, loss_value,loss_metrics)\n",
        "#         print(\"Seen so far: samples\", (step + 1))\n",
        "#     # print(\"Training acc over epoch: %.4f\" train_acc)\n",
        "#     val_losses = 0\n",
        "#     val_metrics=0\n",
        "#     for val_steps,(x_batch_val, y_batch_val) in enumerate(valid_dataset):\n",
        "#         val_metic,val_loss = test_step(x_batch_val, y_batch_val)\n",
        "#         val_losses +=val_loss\n",
        "#         val_metrics +=val_metric\n",
        "#     print(\"Validation loss: %.4f\",(val_losses/val_steps))\n",
        "#     print('validation custom metrics',val_metrics/val_steps)\n",
        "#     print(\"Time taken: %.2fs\" % (time.time() - start_time))\n",
        "#     gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8GwH6gcPnRZ"
      },
      "source": [
        "def read_image(path):\n",
        "    x = cv.imread(path, cv.IMREAD_COLOR)\n",
        "    x = cv.resize(x,(640,480),interpolation=cv.INTER_AREA)\n",
        "    x = x/255.0\n",
        "    x=tf.cast(x,dtype=tf.float32)\n",
        "    return x\n",
        "\n",
        "def read_mask(path):\n",
        "    x = cv.imread(path, cv.IMREAD_GRAYSCALE)\n",
        "    x = cv.resize(x,(640,480),interpolation=cv.INTER_AREA)\n",
        "    x = to_categorical(x,num_classes=no_classes+1)\n",
        "    x = x[:,:,:]\n",
        "    # x = np.expand_dims(x, axis=-1)\n",
        "    # x=np.concatenate([x,x],axis=-1)\n",
        "    x=tf.cast(x,dtype=tf.float32)\n",
        "    return x\n",
        "def custom_metrics(y_true,y_pred,smooth=1):\n",
        "    y_pred = tf.math.argmax(y_pred, axis=-1)\n",
        "    # y_pred = tf.expand_dims(y_pred,axis=-1)\n",
        "    y_pred = tf.one_hot(y_pred,38)\n",
        "    y_true = y_true[:,:,:,1:38]\n",
        "    y_pred= y_pred[:,:,:,1:38]\n",
        "    intersection  = tf.math.reduce_sum((y_true*y_pred),axis = [1,2,3])\n",
        "    union = tf.math.reduce_sum(y_true,axis=[1,2,3])+tf.math.reduce_sum(y_pred,axis = [1,2,3]) - intersection \n",
        "    return tf.math.reduce_mean((intersection+smooth)/(union+smooth),axis=0)\n",
        "def load_data(images,masks):\n",
        "    length = 1990\n",
        "    iou=0\n",
        "    for i,(image,mask) in enumerate(zip(images,masks)):\n",
        "    \n",
        "      img = read_image(image)\n",
        "      mas = read_mask(mask)\n",
        "      img = np.expand_dims(img,0)\n",
        "      mas = np.expand_dims(mas,0)\n",
        "      prediction = model.predict(img)\n",
        "      iou += custom_metrics(mas,prediction)\n",
        "      print(i,iou)\n",
        "    return iou/length\n",
        "no_classes=37\n",
        "print(len(test_x))\n",
        "x=load_data(test_x,test_y)\n",
        "print('*****************************************************************************************************************')\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXH9XLBMM2bB"
      },
      "source": [
        "model2 = main_model2(shape,no_classes)\n",
        "model2=tf.keras.models.load_model(filepath2,custom_objects={'cross_entropy_loss':cross_entropy_loss,'dice_coef':dice_coef,'custom_metrics':custom_metrics})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-gQ6TBDMf4B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZsGANPHM1T5"
      },
      "source": [
        "import matplotlib\n",
        "cmap = matplotlib.colors.ListedColormap(color_list)\n",
        "def plot(image,numpy,prediction):\n",
        "    plt.figure(figsize=(14,14))\n",
        "    plt.subplot(131)\n",
        "    plt.imshow(np.squeeze(prediction)+1,cmap=cmap,vmin=1, vmax=len(color_list))\n",
        "    plt.subplot(132)\n",
        "    plt.imshow(image)\n",
        "    plt.subplot(133)\n",
        "    plt.imshow(numpy,cmap='gray')\n",
        "    print(prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irZ0RNFNVg5q"
      },
      "source": [
        "import matplotlib\n",
        "def plot(image,numpy,prediction):\n",
        "    plt.figure(figsize=(14,14))\n",
        "    plt.subplot(131)\n",
        "    plt.imshow(np.squeeze(prediction),cmap=plt.get_cmap('gray'))\n",
        "    plt.subplot(132)\n",
        "    plt.imshow(image)\n",
        "    plt.subplot(133)\n",
        "    plt.imshow(numpy,cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiDguJ9C-6Pg"
      },
      "source": [
        "def prediction(path):\n",
        "    image = cv.imread(path,cv.IMREAD_COLOR)\n",
        "    x = cv.resize(image,(640,480),interpolation=cv.INTER_NEAREST)\n",
        "    x = x/255.0\n",
        "    x=np.expand_dims(x,0)\n",
        "    y = model.predict(x)\n",
        "    print(y.shape)\n",
        "    numpy = np.zeros((y.shape[1],y.shape[2],y.shape[3]))\n",
        "    print(numpy.shape)\n",
        "    numpy[:,:,:] = y \n",
        "    prediction= numpy.argmax(axis=-1)\n",
        "    print(prediction.shape)\n",
        "    numpy= tf.one_hot(prediction,38)\n",
        "    plot(image,numpy[:,:,2],prediction)\n",
        "    return numpy\n",
        "path = '/content/drive/MyDrive/depth/image/image1.jpg'\n",
        "prediction1=prediction(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb2AVBOiBwYB"
      },
      "source": [
        "for i in range(prediction1.shape[2]):\n",
        "    # for j in range(prediction1.shape[1]):\n",
        "    #     # if prediction1[i,j]>2:\n",
        "    (prediction1.shape)\n",
        "    print(prediction1[])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZIgQWQFHcr7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}